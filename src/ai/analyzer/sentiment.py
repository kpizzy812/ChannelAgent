"""
–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—É—é –æ–∫—Ä–∞—Å–∫—É –ø–æ—Å—Ç–∞ —Å–æ–≥–ª–∞—Å–Ω–æ –¢–ó
"""

import re
from typing import Dict, List, Tuple
from dataclasses import dataclass
from collections import Counter

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ (–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û loguru)
from loguru import logger

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–≥–µ—Ä–∞ –º–æ–¥—É–ª—è
logger = logger.bind(module="sentiment_analyzer")


@dataclass  
class SentimentIndicator:
    """–ò–Ω–¥–∏–∫–∞—Ç–æ—Ä —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏"""
    words: List[str]
    weight: float
    category: str


class SentimentAnalyzer:
    """
    –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
    –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –ø–æ–∑–∏—Ç–∏–≤–Ω—É—é/–Ω–µ–≥–∞—Ç–∏–≤–Ω—É—é/–Ω–µ–π—Ç—Ä–∞–ª—å–Ω—É—é —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å
    """
    
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏"""
        
        # –ü–æ–∑–∏—Ç–∏–≤–Ω—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –¥–ª—è –∫—Ä–∏–ø—Ç–æ/–º–∞–∫—Ä–æ—ç–∫–æ–Ω–æ–º–∏–∫–∏
        self.positive_indicators = SentimentIndicator(
            words=[
                # –†–æ—Å—Ç –∏ —É—Å–ø–µ—Ö
                "—Ä–æ—Å—Ç", "—Ä–∞—Å—Ç–µ—Ç", "—Ä–∞—Å—Ç—É—Ç", "–≤—ã—Ä–æ—Å", "–≤—ã—Ä–æ—Å–ª–∏", "–ø–æ–¥—ä–µ–º", 
                "—É–≤–µ–ª–∏—á–µ–Ω–∏–µ", "–ø—Ä–∏–±—ã–ª—å", "profit", "gain", "gains", "up",
                "bull", "–±—ã—á–∏–π", "bullish", "rally", "—Ä–∞–ª–ª–∏", "boom", "–±—É–º",
                
                # –ü–æ–∑–∏—Ç–∏–≤–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏
                "—Ö–æ—Ä–æ—à–æ", "–æ—Ç–ª–∏—á–Ω–æ", "–ø—Ä–µ–∫—Ä–∞—Å–Ω–æ", "–≤–µ–ª–∏–∫–æ–ª–µ–ø–Ω–æ", "—É—Å–ø–µ—Ö", 
                "—É—Å–ø–µ—à–Ω–æ", "–ø–æ–±–µ–¥–∞", "–¥–æ—Å—Ç–∏–∂–µ–Ω–∏–µ", "breakthrough", "–ø—Ä–æ—Ä—ã–≤",
                "positive", "–ø–æ–∑–∏—Ç–∏–≤–Ω–æ", "good", "great", "excellent",
                "amazing", "awesome", "fantastic", "wonderful",
                
                # –ö—Ä–∏–ø—Ç–æ –ø–æ–∑–∏—Ç–∏–≤
                "moon", "–ª—É–Ω–∞", "ath", "–Ω–æ–≤—ã–π –º–∞–∫—Å–∏–º—É–º", "all time high",
                "adoption", "–ø—Ä–∏–Ω—è—Ç–∏–µ", "institutional", "–∏–Ω—Å—Ç–∏—Ç—É—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π",
                "approval", "–æ–¥–æ–±—Ä–µ–Ω–∏–µ", "etf", "—Ö–∞–ª–≤–∏–Ω–≥", "halving",
                "upgrade", "–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ", "partnership", "–ø–∞—Ä—Ç–Ω–µ—Ä—Å—Ç–≤–æ",
                
                # –ú–∞–∫—Ä–æ –ø–æ–∑–∏—Ç–∏–≤  
                "—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å", "stability", "recovery", "–≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ",
                "employment", "–∑–∞–Ω—è—Ç–æ—Å—Ç—å", "expansion", "—Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ",
                "stimulus", "—Å—Ç–∏–º—É–ª", "support", "–ø–æ–¥–¥–µ—Ä–∂–∫–∞", "confidence",
                "—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å", "strength", "—Å–∏–ª–∞", "resilience", "—É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å",
                
                # –≠–º–æ–¥–∑–∏ –∏ —Å–∏–º–≤–æ–ª—ã
                "üöÄ", "üìà", "üíö", "‚úÖ", "üéâ", "üî•", "üíé", "üëç", "üí∞", "ü§ë",
                "üìä", "+", "üì∂"
            ],
            weight=1.0,
            category="positive"
        )
        
        # –ù–µ–≥–∞—Ç–∏–≤–Ω—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
        self.negative_indicators = SentimentIndicator(
            words=[
                # –ü–∞–¥–µ–Ω–∏–µ –∏ –ø—Ä–æ–±–ª–µ–º—ã
                "–ø–∞–¥–µ–Ω–∏–µ", "–ø–∞–¥–∞–µ—Ç", "–ø–∞–¥–∞—é—Ç", "—É–ø–∞–ª", "—É–ø–∞–ª–∏", "—Å–Ω–∏–∂–µ–Ω–∏–µ",
                "—Å–ø–∞–¥", "–∫—Ä–∏–∑–∏—Å", "–∫—Ä–∞—Ö", "crash", "dump", "–¥–∞–º–ø", "bear",
                "–º–µ–¥–≤–µ–∂–∏–π", "bearish", "down", "drop", "–¥—Ä–æ–ø",
                
                # –ù–µ–≥–∞—Ç–∏–≤–Ω—ã–µ —ç–º–æ—Ü–∏–∏
                "–ø–ª–æ—Ö–æ", "—É–∂–∞—Å–Ω–æ", "–∫–∞—Ç–∞—Å—Ç—Ä–æ—Ñ–∞", "–ø—Ä–æ–≤–∞–ª", "–Ω–µ—É–¥–∞—á–∞", 
                "–ø—Ä–æ–±–ª–µ–º–∞", "–ø—Ä–æ–±–ª–µ–º—ã", "bad", "terrible", "awful", "horrible",
                "disaster", "–∫–∞—Ç–∞—Å—Ç—Ä–æ—Ñ–∞", "crisis", "fear", "—Å—Ç—Ä–∞—Ö", "panic",
                "–ø–∞–Ω–∏–∫–∞", "worry", "–±–µ—Å–ø–æ–∫–æ–π—Å—Ç–≤–æ", "concern", "–æ–ø–∞—Å–µ–Ω–∏–µ",
                
                # –ö—Ä–∏–ø—Ç–æ –Ω–µ–≥–∞—Ç–∏–≤
                "—Å–∫–∞–º", "scam", "hack", "—Ö–∞–∫", "–≤–∑–ª–æ–º", "rug pull", 
                "liquidation", "–ª–∏–∫–≤–∏–¥–∞—Ü–∏—è", "rekt", "fud", "—Ñ—É–¥",
                "ban", "–∑–∞–ø—Ä–µ—Ç", "regulation", "—Ä–µ–≥—É–ª–∏—Ä–æ–≤–∞–Ω–∏–µ",
                "sec", "lawsuit", "–∏—Å–∫", "fine", "—à—Ç—Ä–∞—Ñ",
                
                # –ú–∞–∫—Ä–æ –Ω–µ–≥–∞—Ç–∏–≤
                "inflation", "–∏–Ω—Ñ–ª—è—Ü–∏—è", "recession", "—Ä–µ—Ü–µ—Å—Å–∏—è", 
                "unemployment", "–±–µ–∑—Ä–∞–±–æ—Ç–∏—Ü–∞", "debt", "–¥–æ–ª–≥", "deficit",
                "–¥–µ—Ñ–∏—Ü–∏—Ç", "bubble", "–ø—É–∑—ã—Ä—å", "collapse", "–∫–æ–ª–ª–∞–ø—Å",
                "slowdown", "–∑–∞–º–µ–¥–ª–µ–Ω–∏–µ", "contraction", "—Å–∂–∞—Ç–∏–µ",
                
                # –≠–º–æ–¥–∑–∏ –∏ —Å–∏–º–≤–æ–ª—ã
                "üìâ", "‚ùå", "üî¥", "üíî", "üò®", "üò±", "‚ö†Ô∏è", "üö®", "üí∏", "üìä",
                "-", "‚Üì", "‚¨áÔ∏è"
            ],
            weight=1.0,
            category="negative"
        )
        
        # –ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã (—Ñ–∞–∫—Ç—ã, –∞–Ω–∞–ª–∏—Ç–∏–∫–∞)
        self.neutral_indicators = SentimentIndicator(
            words=[
                # –ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã
                "–∞–Ω–∞–ª–∏–∑", "analysis", "–¥–∞–Ω–Ω—ã–µ", "data", "—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞", 
                "statistics", "–æ—Ç—á–µ—Ç", "report", "–∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ", "research",
                "–ø—Ä–æ–≥–Ω–æ–∑", "forecast", "prediction", "–ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ",
                "—Ç—Ä–µ–Ω–¥", "trend", "pattern", "–ø–∞—Ç—Ç–µ—Ä–Ω", "correlation",
                "–∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è", "indicator", "–∏–Ω–¥–∏–∫–∞—Ç–æ—Ä",
                
                # –§–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã
                "—Å–æ–≥–ª–∞—Å–Ω–æ", "according", "–ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç", "shows", "reveals",
                "—Ä–∞—Å–∫—Ä—ã–≤–∞–µ—Ç", "indicates", "—É–∫–∞–∑—ã–≤–∞–µ—Ç", "suggests", 
                "–ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç", "confirms", "–ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç", "demonstrates",
                "–¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç", "explains", "–æ–±—ä—è—Å–Ω—è–µ—Ç",
                
                # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã
                "—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π", "technical", "—Ñ—É–Ω–¥–∞–º–µ–Ω—Ç–∞–ª—å–Ω—ã–π", "fundamental",
                "volume", "–æ–±—ä–µ–º", "price", "—Ü–µ–Ω–∞", "level", "—É—Ä–æ–≤–µ–Ω—å",
                "support", "–ø–æ–¥–¥–µ—Ä–∂–∫–∞", "resistance", "—Å–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏–µ",
                "moving average", "—Å–∫–æ–ª—å–∑—è—â–∞—è —Å—Ä–µ–¥–Ω—è—è", "rsi", "macd",
                
                # –ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã–µ —ç–º–æ–¥–∑–∏
                "üìä", "üìà", "üìâ", "üîç", "üìù", "üí≠", "ü§î", "üìã", "üìå"
            ],
            weight=0.8,
            category="neutral"
        )
        
        # –£—Å–∏–ª–∏—Ç–µ–ª–∏ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏
        self.amplifiers = {
            "–æ—á–µ–Ω—å": 1.5, "very": 1.5, "–∫—Ä–∞–π–Ω–µ": 1.7, "extremely": 1.7,
            "–Ω–µ–≤–µ—Ä–æ—è—Ç–Ω–æ": 1.8, "incredibly": 1.8, "–∏—Å–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–æ": 1.6,
            "exceptionally": 1.6, "—á—Ä–µ–∑–≤—ã—á–∞–π–Ω–æ": 1.7, "extraordinarily": 1.7,
            "—Å—É–ø–µ—Ä": 1.4, "super": 1.4, "–º–µ–≥–∞": 1.3, "mega": 1.3,
            "–≥–∏–ø–µ—Ä": 1.6, "hyper": 1.6, "—É–ª—å—Ç—Ä–∞": 1.5, "ultra": 1.5
        }
        
        # –û—Å–ª–∞–±–∏—Ç–µ–ª–∏ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏  
        self.diminishers = {
            "–Ω–µ–º–Ω–æ–≥–æ": 0.7, "slightly": 0.7, "—á—É—Ç—å": 0.6, "somewhat": 0.8,
            "–¥–æ–≤–æ–ª—å–Ω–æ": 0.9, "rather": 0.9, "–æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ": 0.8, 
            "relatively": 0.8, "—á–∞—Å—Ç–∏—á–Ω–æ": 0.7, "partially": 0.7
        }
        
        logger.debug("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏")
    
    def analyze_sentiment(
        self, 
        text: str, 
        image_description: str = None
    ) -> Dict[str, any]:
        """
        –ê–Ω–∞–ª–∏–∑ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        
        Args:
            text: –¢–µ–∫—Å—Ç –ø–æ—Å—Ç–∞
            image_description: –û–ø–∏—Å–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏
        """
        try:
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç
            combined_text = self._prepare_text(text, image_description)
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å
            sentiment_scores = self._calculate_sentiment_scores(combined_text)
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏—Ç–æ–≥–æ–≤—É—é —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å
            final_sentiment = self._determine_final_sentiment(sentiment_scores)
            
            # –ù–∞—Ö–æ–¥–∏–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞-–∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
            found_indicators = self._extract_indicators(combined_text)
            
            result = {
                "sentiment": final_sentiment,
                "scores": sentiment_scores,
                "confidence": self._calculate_confidence(sentiment_scores),
                "found_indicators": found_indicators,
                "text_length": len(combined_text)
            }
            
            logger.debug("–ê–Ω–∞–ª–∏–∑ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏: {}, —Å—á–µ—Ç–∞={}, —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å={:.1f}%", 
                        final_sentiment, sentiment_scores, result["confidence"])
            
            return result
            
        except Exception as e:
            logger.error("–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏: {}", str(e))
            return {
                "sentiment": "–Ω–µ–π—Ç—Ä–∞–ª—å–Ω–∞—è",
                "scores": {"positive": 0, "negative": 0, "neutral": 0},
                "confidence": 0,
                "error": str(e)
            }
    
    def _prepare_text(self, text: str, image_description: str = None) -> str:
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å —Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"""
        combined_parts = []
        
        if text:
            combined_parts.append(text)
        
        if image_description:
            combined_parts.append(image_description)
        
        combined_text = " ".join(combined_parts).lower()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —ç–º–æ–¥–∑–∏ –∏ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏
        return combined_text
    
    def _calculate_sentiment_scores(self, text: str) -> Dict[str, float]:
        """–í—ã—á–∏—Å–ª–∏—Ç—å —Å—á–µ—Ç–∞ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏"""
        
        scores = {"positive": 0.0, "negative": 0.0, "neutral": 0.0}
        
        # –†–∞–∑–±–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ —Å–ª–æ–≤–∞
        words = text.split()
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥–æ–µ —Å–ª–æ–≤–æ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
        for i, word in enumerate(words):
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
            positive_match = self._check_word_match(word, self.positive_indicators.words)
            if positive_match:
                multiplier = self._get_context_multiplier(words, i)
                scores["positive"] += self.positive_indicators.weight * multiplier
                
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
            negative_match = self._check_word_match(word, self.negative_indicators.words)
            if negative_match:
                multiplier = self._get_context_multiplier(words, i)
                scores["negative"] += self.negative_indicators.weight * multiplier
                
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
            neutral_match = self._check_word_match(word, self.neutral_indicators.words)
            if neutral_match:
                multiplier = self._get_context_multiplier(words, i)
                scores["neutral"] += self.neutral_indicators.weight * multiplier
        
        return scores
    
    def _check_word_match(self, word: str, indicators: List[str]) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å–ª–æ–≤–∞ —Å –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞–º–∏"""
        word_clean = re.sub(r'[^\w]', '', word).lower()
        
        for indicator in indicators:
            # –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
            if word_clean == indicator.lower():
                return True
            
            # –ß–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –¥–ª—è –¥–ª–∏–Ω–Ω—ã—Ö —Å–ª–æ–≤
            if len(indicator) > 4 and indicator.lower() in word_clean:
                return True
                
            # –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ —ç–º–æ–¥–∑–∏
            if indicator in word:
                return True
        
        return False
    
    def _get_context_multiplier(self, words: List[str], position: int) -> float:
        """–ü–æ–ª—É—á–∏—Ç—å –º–Ω–æ–∂–∏—Ç–µ–ª—å –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ —Å–ª–æ–≤–∞"""
        multiplier = 1.0
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É—Å–∏–ª–∏—Ç–µ–ª–∏ –ø–µ—Ä–µ–¥ —Å–ª–æ–≤–æ–º
        if position > 0:
            prev_word = re.sub(r'[^\w]', '', words[position - 1]).lower()
            if prev_word in self.amplifiers:
                multiplier *= self.amplifiers[prev_word]
            elif prev_word in self.diminishers:
                multiplier *= self.diminishers[prev_word]
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Ç—Ä–∏—Ü–∞–Ω–∏–µ
        negation_words = ["–Ω–µ", "–Ω–µ—Ç", "–±–µ–∑", "not", "no", "without", "never"]
        for i in range(max(0, position - 2), position):
            if i < len(words):
                prev_word = re.sub(r'[^\w]', '', words[i]).lower()
                if prev_word in negation_words:
                    multiplier *= -0.8  # –ò–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∏ –æ—Å–ª–∞–±–ª—è–µ–º
                    break
        
        return multiplier
    
    def _determine_final_sentiment(self, scores: Dict[str, float]) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∏—Ç–æ–≥–æ–≤—É—é —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å"""
        
        # –ï—Å–ª–∏ –≤—Å–µ —Å—á–µ—Ç–∞ –±–ª–∏–∑–∫–∏ –∫ –Ω—É–ª—é - –Ω–µ–π—Ç—Ä–∞–ª—å–Ω–∞—è
        total_score = sum(abs(score) for score in scores.values())
        if total_score < 0.5:
            return "–Ω–µ–π—Ç—Ä–∞–ª—å–Ω–∞—è"
        
        # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–µ –∏ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–µ —Å—á–µ—Ç–∞
        positive_score = scores["positive"] 
        negative_score = abs(scores["negative"])  # –ë–µ—Ä–µ–º –º–æ–¥—É–ª—å
        neutral_score = scores["neutral"]
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–æ–º–∏–Ω–∏—Ä—É—é—â—É—é —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å
        max_score = max(positive_score, negative_score, neutral_score)
        
        if max_score == positive_score and positive_score > negative_score * 1.2:
            return "–ø–æ–∑–∏—Ç–∏–≤–Ω–∞—è"
        elif max_score == negative_score and negative_score > positive_score * 1.2:
            return "–Ω–µ–≥–∞—Ç–∏–≤–Ω–∞—è"
        else:
            return "–Ω–µ–π—Ç—Ä–∞–ª—å–Ω–∞—è"
    
    def _calculate_confidence(self, scores: Dict[str, float]) -> float:
        """–í—ã—á–∏—Å–ª–∏—Ç—å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏"""
        
        total_score = sum(abs(score) for score in scores.values())
        if total_score == 0:
            return 0.0
        
        # –ù–∞—Ö–æ–¥–∏–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –∏ –≤—Ç–æ—Ä–æ–π –ø–æ –≤–µ–ª–∏—á–∏–Ω–µ —Å—á–µ—Ç
        sorted_scores = sorted([abs(score) for score in scores.values()], reverse=True)
        
        if len(sorted_scores) < 2:
            return 50.0
        
        max_score = sorted_scores[0]
        second_score = sorted_scores[1]
        
        # –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Ä–∞–∑—Ä—ã–≤–∞ –º–µ–∂–¥—É –ø–µ—Ä–≤—ã–º –∏ –≤—Ç–æ—Ä—ã–º –º–µ—Å—Ç–æ–º
        if second_score == 0:
            confidence = 95.0
        else:
            gap = (max_score - second_score) / max_score
            confidence = min(95.0, 50.0 + gap * 45.0)
        
        return round(confidence, 1)
    
    def _extract_indicators(self, text: str) -> Dict[str, List[str]]:
        """–ò–∑–≤–ª–µ—á—å –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏"""
        
        found = {"positive": [], "negative": [], "neutral": []}
        words = text.split()
        
        for word in words:
            # –ü–æ–∑–∏—Ç–∏–≤–Ω—ã–µ
            if self._check_word_match(word, self.positive_indicators.words):
                clean_word = re.sub(r'[^\w\u263a-\U0001f645]', '', word)
                if clean_word and clean_word not in found["positive"]:
                    found["positive"].append(clean_word)
                    
            # –ù–µ–≥–∞—Ç–∏–≤–Ω—ã–µ  
            if self._check_word_match(word, self.negative_indicators.words):
                clean_word = re.sub(r'[^\w\u263a-\U0001f645]', '', word)
                if clean_word and clean_word not in found["negative"]:
                    found["negative"].append(clean_word)
                    
            # –ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã–µ
            if self._check_word_match(word, self.neutral_indicators.words):
                clean_word = re.sub(r'[^\w\u263a-\U0001f645]', '', word)
                if clean_word and clean_word not in found["neutral"]:
                    found["neutral"].append(clean_word)
        
        return found
    
    def get_sentiment_stats(self) -> Dict[str, int]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏"""
        return {
            "positive_indicators": len(self.positive_indicators.words),
            "negative_indicators": len(self.negative_indicators.words), 
            "neutral_indicators": len(self.neutral_indicators.words),
            "amplifiers": len(self.amplifiers),
            "diminishers": len(self.diminishers)
        }
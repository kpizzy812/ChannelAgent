"""
OpenAI API –∫–ª–∏–µ–Ω—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
–û–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ —Å OpenAI API —Å–æ–≥–ª–∞—Å–Ω–æ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º –¢–ó
"""

import asyncio
import base64
from typing import Optional, Dict, Any, List
from pathlib import Path

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ (–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û loguru)
from loguru import logger

# –°—Ç–æ—Ä–æ–Ω–Ω–∏–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏
import openai
from openai import AsyncOpenAI

# –õ–æ–∫–∞–ª—å–Ω—ã–µ –∏–º–ø–æ—Ä—Ç—ã
from src.utils.config import get_config
from src.utils.exceptions import AIProcessingError
from src.ai.emoji_pool import get_emoji_prompt_section

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–≥–µ—Ä–∞ –º–æ–¥—É–ª—è
logger = logger.bind(module="ai_client")


class OpenAIClient:
    """
    –ö–ª–∏–µ–Ω—Ç –¥–ª—è –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å OpenAI API
    –†–µ–∞–ª–∏–∑—É–µ—Ç –∞–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞ –∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å–æ–≥–ª–∞—Å–Ω–æ –¢–ó
    """
    
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è OpenAI –∫–ª–∏–µ–Ω—Ç–∞"""
        self.config = get_config()
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∫–ª–∏–µ–Ω—Ç OpenAI
        self.client = AsyncOpenAI(
            api_key=self.config.OPENAI_API_KEY
        )
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –∑–∞–ø—Ä–æ—Å–æ–≤
        self.text_model = self.config.OPENAI_MODEL
        self.vision_model = "gpt-4-vision-preview"  # –î–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        self.default_temperature = 0.3  # –ù–∏–∑–∫–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è –±–æ–ª–µ–µ —Å—Ç–∞–±–∏–ª—å–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        self.default_max_tokens = 1500   # –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏ —Ä–µ—Å—Ç–∞–π–ª–∏–Ω–≥–∞
        
        logger.info("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω OpenAI –∫–ª–∏–µ–Ω—Ç —Å –º–æ–¥–µ–ª—å—é: {}", self.text_model)
    
    async def analyze_relevance_and_sentiment(
        self,
        text: str,
        image_description: Optional[str] = None,
        user_examples: Optional[List[str]] = None,
        max_retries: int = 3
    ) -> Dict[str, Any]:
        """
        –ê–Ω–∞–ª–∏–∑ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –∏ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        
        Args:
            text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç –ø–æ—Å—Ç–∞
            image_description: –û–ø–∏—Å–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–µ—Å–ª–∏ –µ—Å—Ç—å)
            user_examples: –ü—Ä–∏–º–µ—Ä—ã –ø–æ—Å—Ç–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è —Å—Ç–∏–ª—è
            max_retries: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞
        """
        
        for attempt in range(max_retries):
            try:
                logger.debug("–ê–Ω–∞–ª–∏–∑ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –∏ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ (–ø–æ–ø—ã—Ç–∫–∞ {})", attempt + 1)
                
                # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–º–ø—Ç —Å–æ–≥–ª–∞—Å–Ω–æ –¢–ó
                prompt = self._build_analysis_prompt(text, image_description, user_examples)
                
                # –í—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ OpenAI
                response = await self.client.chat.completions.create(
                    model=self.text_model,
                    messages=[
                        {"role": "system", "content": "–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É –∏ —Å—Ç–∞–π–ª–∏–Ω–≥—É –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –≤ —Å—Ñ–µ—Ä–µ –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç –∏ –º–∞–∫—Ä–æ—ç–∫–æ–Ω–æ–º–∏–∫–∏."},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=self.default_temperature,
                    max_tokens=self.default_max_tokens
                )
                
                # –ü–∞—Ä—Å–∏–º –æ—Ç–≤–µ—Ç
                result = self._parse_analysis_response(response.choices[0].message.content)
                
                logger.info("–ê–Ω–∞–ª–∏–∑ –≤—ã–ø–æ–ª–Ω–µ–Ω: —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å={}, —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å={}", 
                          result.get("relevance_score"), result.get("sentiment"))
                
                return result
                
            except openai.RateLimitError as e:
                logger.warning("Rate limit OpenAI (–ø–æ–ø—ã—Ç–∫–∞ {}): {}", attempt + 1, str(e))
                if attempt < max_retries - 1:
                    await asyncio.sleep(2 ** attempt)  # Exponential backoff
                continue
                
            except openai.APIError as e:
                logger.error("–û—à–∏–±–∫–∞ OpenAI API: {}", str(e))
                if attempt == max_retries - 1:
                    raise AIProcessingError(f"OpenAI API error: {str(e)}")
                await asyncio.sleep(1)
                
            except Exception as e:
                logger.error("–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {}", str(e))
                if attempt == max_retries - 1:
                    raise AIProcessingError(f"Unexpected error: {str(e)}")
                await asyncio.sleep(1)
        
        raise AIProcessingError("–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å –∞–Ω–∞–ª–∏–∑ –ø–æ—Å–ª–µ –≤—Å–µ—Ö –ø–æ–ø—ã—Ç–æ–∫")
    
    async def analyze_image(self, image_data: bytes, max_retries: int = 3) -> str:
        """
        –ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –ø–æ–º–æ—â—å—é Vision API
        
        Args:
            image_data: –ë–∞–π—Ç—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            max_retries: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫
            
        Returns:
            –û–ø–∏—Å–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        """
        
        for attempt in range(max_retries):
            try:
                logger.debug("–ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ Vision API (–ø–æ–ø—ã—Ç–∫–∞ {})", attempt + 1)
                
                # –ö–æ–¥–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ base64
                image_base64 = base64.b64encode(image_data).decode('utf-8')
                
                # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                response = await self.client.chat.completions.create(
                    model=self.vision_model,
                    messages=[
                        {
                            "role": "user",
                            "content": [
                                {
                                    "type": "text", 
                                    "text": "–û–ø–∏—à–∏ —ç—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ–¥—Ä–æ–±–Ω–æ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ. –°–æ—Å—Ä–µ–¥–æ—Ç–æ—á—å—Å—è –Ω–∞ –∫–ª—é—á–µ–≤–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏, —Ç–µ–∫—Å—Ç–µ, –≥—Ä–∞—Ñ–∏–∫–∞—Ö, –ª—é–¥—è—Ö –∏ –æ–±—ä–µ–∫—Ç–∞—Ö. –≠—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–∑ –ø–æ—Å—Ç–∞ –æ –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç–∞—Ö/–º–∞–∫—Ä–æ—ç–∫–æ–Ω–æ–º–∏–∫–µ/–±–ª–æ–∫—á–µ–π–Ω."
                                },
                                {
                                    "type": "image_url",
                                    "image_url": {
                                        "url": f"data:image/jpeg;base64,{image_base64}",
                                        "detail": "high"
                                    }
                                }
                            ]
                        }
                    ],
                    temperature=0.3,
                    max_tokens=800
                )
                
                description = response.choices[0].message.content.strip()
                
                logger.info("–ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤—ã–ø–æ–ª–Ω–µ–Ω: {} —Å–∏–º–≤–æ–ª–æ–≤", len(description))
                
                return description
                
            except openai.RateLimitError as e:
                logger.warning("Rate limit –¥–ª—è Vision API: {}", str(e))
                if attempt < max_retries - 1:
                    await asyncio.sleep(3 ** attempt)
                continue
                
            except Exception as e:
                logger.error("–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {}", str(e))
                if attempt == max_retries - 1:
                    return "–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ"
                await asyncio.sleep(2)
        
        return "–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"
    
    async def stylize_user_content(
        self,
        original_text: str,
        user_examples: List[str],
        category: Optional[str] = None,
        max_retries: int = 3
    ) -> Dict[str, Any]:
        """
        –°—Ç–∏–ª–∏–∑–∞—Ü–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –ø–æ–¥ —Å—Ç–∏–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        
        Args:
            original_text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è —Å—Ç–∏–ª–∏–∑–∞—Ü–∏–∏
            user_examples: –ü—Ä–∏–º–µ—Ä—ã –ø–æ—Å—Ç–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            category: –ö–∞—Ç–µ–≥–æ—Ä–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            max_retries: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç —Å—Ç–∏–ª–∏–∑–∞—Ü–∏–∏
        """
        
        for attempt in range(max_retries):
            try:
                logger.debug("–°—Ç–∏–ª–∏–∑–∞—Ü–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ (–ø–æ–ø—ã—Ç–∫–∞ {})", attempt + 1)
                
                # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è —Å—Ç–∏–ª–∏–∑–∞—Ü–∏–∏
                prompt = self._build_stylization_prompt(original_text, user_examples, category)
                
                # –í—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ OpenAI
                response = await self.client.chat.completions.create(
                    model=self.text_model,
                    messages=[
                        {"role": "system", "content": "–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Å—Ç–∞–π–ª–∏–Ω–≥—É Telegram –ø–æ—Å—Ç–æ–≤. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ - –ø–µ—Ä–µ–¥–µ–ª–∞—Ç—å –ø–æ—Å—Ç –ø–æ–¥ —Å—Ç–∏–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, —Å–æ—Ö—Ä–∞–Ω–∏–≤ –∫–ª—é—á–µ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é."},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.4,  # –ù–µ–º–Ω–æ–≥–æ –≤—ã—à–µ –¥–ª—è –±–æ–ª–µ–µ –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ–π —Å—Ç–∏–ª–∏–∑–∞—Ü–∏–∏
                    max_tokens=1200
                )
                
                # –ü–∞—Ä—Å–∏–º –æ—Ç–≤–µ—Ç
                result = self._parse_stylization_response(response.choices[0].message.content)
                
                logger.info("–°—Ç–∏–ª–∏–∑–∞—Ü–∏—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∞: –∫–∞—Ç–µ–≥–æ—Ä–∏—è={}, –∏–∑–º–µ–Ω–µ–Ω–∏—è={}",
                           result.get("category", "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–∞"), 
                           original_text != result.get("stylized_text", ""))
                
                return result
                
            except openai.RateLimitError as e:
                logger.warning("Rate limit –ø—Ä–∏ —Å—Ç–∏–ª–∏–∑–∞—Ü–∏–∏ (–ø–æ–ø—ã—Ç–∫–∞ {}): {}", attempt + 1, str(e))
                if attempt < max_retries - 1:
                    await asyncio.sleep(2 ** attempt)
                continue
                
            except Exception as e:
                logger.error("–û—à–∏–±–∫–∞ —Å—Ç–∏–ª–∏–∑–∞—Ü–∏–∏: {}", str(e))
                if attempt == max_retries - 1:
                    return {
                        "success": False,
                        "stylized_text": original_text,
                        "category": category,
                        "error": str(e)
                    }
                await asyncio.sleep(1)
        
        return {
            "success": False, 
            "stylized_text": original_text,
            "category": category,
            "error": "–ü—Ä–µ–≤—ã—à–µ–Ω–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫"
        }
    
    async def uniqualize_content(
        self,
        original_text: str,
        user_examples: List[str],
        source_channel_title: Optional[str] = None,
        source_channel_username: Optional[str] = None,
        max_retries: int = 3
    ) -> Dict[str, Any]:
        """
        –≠–¢–ê–ü 1: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —É–Ω–∏–∫–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        –ö–∞—Ä–¥–∏–Ω–∞–ª—å–Ω–æ –ø–µ—Ä–µ–¥–µ–ª—ã–≤–∞–µ—Ç –ø–æ—Å—Ç, —Å–æ—Ö—Ä–∞–Ω—è—è —Å–º—ã—Å–ª –∏ –∫–ª—é—á–µ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ

        Args:
            original_text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç –ø–æ—Å—Ç–∞
            user_examples: –ü—Ä–∏–º–µ—Ä—ã –ø–æ—Å—Ç–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è —Å—Ç–∏–ª—è
            source_channel_title: –ù–∞–∑–≤–∞–Ω–∏–µ –∫–∞–Ω–∞–ª–∞-–∏—Å—Ç–æ—á–Ω–∏–∫–∞ (–¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è –±—Ä–µ–Ω–¥–∏–Ω–≥–∞)
            source_channel_username: Username –∫–∞–Ω–∞–ª–∞-–∏—Å—Ç–æ—á–Ω–∏–∫–∞ (–¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è @—É–ø–æ–º–∏–Ω–∞–Ω–∏–π)
            max_retries: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫

        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç —É–Ω–∏–∫–∞–ª–∏–∑–∞—Ü–∏–∏
        """
        
        for attempt in range(max_retries):
            try:
                logger.debug("–≠—Ç–∞–ø 1: –£–Ω–∏–∫–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞ (–ø–æ–ø—ã—Ç–∫–∞ {})", attempt + 1)

                # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è —É–Ω–∏–∫–∞–ª–∏–∑–∞—Ü–∏–∏ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∞
                prompt = self._build_uniqualization_prompt(
                    original_text,
                    user_examples,
                    source_channel_title,
                    source_channel_username
                )
                
                # –í—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ OpenAI
                response = await self.client.chat.completions.create(
                    model=self.text_model,
                    messages=[
                        {"role": "system", "content": "–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —É–Ω–∏–∫–∞–ª–∏–∑–∞—Ü–∏–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ - –∫–∞—Ä–¥–∏–Ω–∞–ª—å–Ω–æ –ø–µ—Ä–µ–¥–µ–ª–∞—Ç—å –ø–æ—Å—Ç, –ø–æ–ª–Ω–æ—Å—Ç—å—é –∏–∑–º–µ–Ω–∏–≤ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∏ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏, –Ω–æ —Å–æ—Ö—Ä–∞–Ω–∏–≤ –≤—Å–µ –≤–∞–∂–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏ —Å–º—ã—Å–ª."},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.7,  # –í—ã—Å–æ–∫–∞—è –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç—å –¥–ª—è —É–Ω–∏–∫–∞–ª–∏–∑–∞—Ü–∏–∏
                    max_tokens=1500
                )
                
                # –ü–æ–ª—É—á–∞–µ–º RAW –æ—Ç–≤–µ—Ç –æ—Ç AI
                raw_response = response.choices[0].message.content
                
                # üîç DEBUG: –ü–æ–ª–Ω—ã–π RAW –æ—Ç–≤–µ—Ç AI –Ω–∞ —ç—Ç–∞–ø–µ 1
                logger.info("üéØ –≠–¢–ê–ü 1 - RAW –û–¢–í–ï–¢ AI:\n{}", repr(raw_response))
                logger.info("üéØ –≠–¢–ê–ü 1 - –í–ò–ó–£–ê–õ–¨–ù–´–ô –û–¢–í–ï–¢ AI:\n{}", raw_response)
                
                # –ü–∞—Ä—Å–∏–º –æ—Ç–≤–µ—Ç
                result = self._parse_uniqualization_response(raw_response)
                
                # üîç DEBUG: –†–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ—Å–ª–µ –ø–∞—Ä—Å–∏–Ω–≥–∞
                logger.info("üîß –≠–¢–ê–ü 1 - –ü–û–°–õ–ï –ü–ê–†–°–ò–ù–ì–ê:\n{}", repr(result.get("uniqualized_text", "")))
                
                logger.info("–≠—Ç–∞–ø 1 –∑–∞–≤–µ—Ä—à–µ–Ω: —É–Ω–∏–∫–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞, –∏–∑–º–µ–Ω–µ–Ω–∏–π={}",
                           original_text != result.get("uniqualized_text", ""))
                
                return result
                
            except Exception as e:
                logger.error("–û—à–∏–±–∫–∞ —É–Ω–∏–∫–∞–ª–∏–∑–∞—Ü–∏–∏ (–ø–æ–ø—ã—Ç–∫–∞ {}): {}", attempt + 1, str(e))
                if attempt == max_retries - 1:
                    return {
                        "success": False,
                        "uniqualized_text": original_text,
                        "error": str(e)
                    }
                await asyncio.sleep(1)
        
        return {
            "success": False, 
            "uniqualized_text": original_text,
            "error": "–ü—Ä–µ–≤—ã—à–µ–Ω–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫"
        }
    
    async def format_with_markdown(
        self,
        text: str,
        max_retries: int = 3
    ) -> Dict[str, Any]:
        """
        –≠–¢–ê–ü 2: –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ Markdown —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è Telethon
        –î–æ–±–∞–≤–ª—è–µ—Ç **–∂–∏—Ä–Ω—ã–π** –∏ __–∫—É—Ä—Å–∏–≤__ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

        Args:
            text: –£–Ω–∏–∫–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
            max_retries: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫

        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç Markdown —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        """
        
        for attempt in range(max_retries):
            try:
                logger.debug("–≠—Ç–∞–ø 2: Markdown —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ (–ø–æ–ø—ã—Ç–∫–∞ {})", attempt + 1)

                # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è Markdown —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
                prompt = self._build_markdown_formatting_prompt(text)

                # –í—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ OpenAI
                response = await self.client.chat.completions.create(
                    model=self.text_model,
                    messages=[
                        {"role": "system", "content": "–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ Markdown —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—é. –î–æ–±–∞–≤–ª—è–π **–∂–∏—Ä–Ω—ã–π** –∏ __–∫—É—Ä—Å–∏–≤__ –≥–¥–µ –Ω—É–∂–Ω–æ. –ù–ï –ú–ï–ù–Ø–ô —ç–º–æ–¥–∑–∏ –∏ —Ç–µ–∫—Å—Ç!"},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.1,  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –Ω–∏–∑–∫–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
                    max_tokens=1500
                )
                
                # –ü–∞—Ä—Å–∏–º –æ—Ç–≤–µ—Ç –ë–ï–ó –≤–∞–ª–∏–¥–∞—Ü–∏–∏ HTML (AI —Å–∞–º –∫–æ—Ä—Ä–µ–∫—Ç–µ–Ω)
                formatted_text = response.choices[0].message.content.strip()
                
                # üîç DEBUG: –ü–æ–ª–Ω—ã–π RAW –æ—Ç–≤–µ—Ç AI –Ω–∞ —ç—Ç–∞–ø–µ 2
                logger.info("üé® –≠–¢–ê–ü 2 - RAW –û–¢–í–ï–¢ AI:\n{}", repr(formatted_text))
                logger.info("üé® –≠–¢–ê–ü 2 - –í–ò–ó–£–ê–õ–¨–ù–´–ô –û–¢–í–ï–¢ AI:\n{}", formatted_text)
                
                # –£–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ markdown –∫–æ–¥ –±–ª–æ–∫–∏ –µ—Å–ª–∏ AI –∏—Ö –¥–æ–±–∞–≤–∏–ª
                cleaned_text = self._clean_markdown_code_blocks(formatted_text)
                
                # üîç DEBUG: –ü–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏ markdown
                if cleaned_text != formatted_text:
                    logger.info("üßπ –û–ß–ò–©–ï–ù–´ MARKDOWN –ë–õ–û–ö–ò: {} -> {} —Å–∏–º–≤–æ–ª–æ–≤", 
                               len(formatted_text), len(cleaned_text))
                    logger.info("üßπ –†–ï–ó–£–õ–¨–¢–ê–¢ –ü–û–°–õ–ï –û–ß–ò–°–¢–ö–ò:\n{}", repr(cleaned_text))
                
                # üö® –ö–†–ò–¢–ò–ß–ù–û: –ó–∞–º–µ–Ω—è–µ–º –ª–∏—Ç–µ—Ä–∞–ª—å–Ω—ã–µ \n –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫
                final_text = cleaned_text.replace('\\n', '\n')
                
                # üîç DEBUG: –ü–æ—Å–ª–µ –∑–∞–º–µ–Ω—ã \n
                if final_text != cleaned_text:
                    logger.info("üîß –ó–ê–ú–ï–ù–ï–ù–´ –õ–ò–¢–ï–†–ê–õ–¨–ù–´–ï \\n: {} -> {} —Å–∏–º–≤–æ–ª–æ–≤", 
                               len(cleaned_text), len(final_text))
                    logger.info("üîß –†–ï–ó–£–õ–¨–¢–ê–¢ –ü–û–°–õ–ï –ó–ê–ú–ï–ù–´ \\n:\n{}", repr(final_text))
                
                # Markdown –æ—Ç AI –≥–æ—Ç–æ–≤ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é
                logger.info("‚úÖ –§–∏–Ω–∞–ª—å–Ω—ã–π Markdown –≥–æ—Ç–æ–≤: {} —Å–∏–º–≤–æ–ª–æ–≤", len(final_text))

                result = {
                    "success": True,
                    "formatted_text": final_text,
                    "raw_response": formatted_text
                }

                logger.info("–≠—Ç–∞–ø 2 –∑–∞–≤–µ—Ä—à–µ–Ω: Markdown —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–æ")

                return result

            except Exception as e:
                logger.error("–û—à–∏–±–∫–∞ Markdown —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (–ø–æ–ø—ã—Ç–∫–∞ {}): {}", attempt + 1, str(e))
                if attempt == max_retries - 1:
                    return {
                        "success": False,
                        "formatted_text": text,
                        "error": str(e)
                    }
                await asyncio.sleep(1)
        
        return {
            "success": False, 
            "formatted_text": text,
            "error": "–ü—Ä–µ–≤—ã—à–µ–Ω–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫"
        }
    
    def _build_stylization_prompt(
        self,
        original_text: str,
        user_examples: List[str],
        category: Optional[str]
    ) -> str:
        """–ü–æ—Å—Ç—Ä–æ–∏—Ç—å –ø—Ä–æ–º–ø—Ç –¥–ª—è —Å—Ç–∏–ª–∏–∑–∞—Ü–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
        
        prompt_parts = [
            "–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Å—Ç–∞–π–ª–∏–Ω–≥—É Telegram –ø–æ—Å—Ç–æ–≤ –≤ –∫—Ä–∏–ø—Ç–æ/–º–∞–∫—Ä–æ—ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–æ–π —Å—Ñ–µ—Ä–µ.",
            "",
            "–ü–†–ò–ú–ï–†–´ –ú–û–ï–ì–û –°–¢–ò–õ–Ø:"
        ]
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–∏–º–µ—Ä—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        for i, example in enumerate(user_examples[:3], 1):
            prompt_parts.append(f"–ü—Ä–∏–º–µ—Ä {i}: {example}")
        
        prompt_parts.extend([
            "",
            "–ó–ê–î–ê–ß–ê: –ü–µ—Ä–µ–¥–µ–ª–∞–π —Å–ª–µ–¥—É—é—â–∏–π –ø–æ—Å—Ç –ø–æ–¥ –º–æ–π —Å—Ç–∏–ª—å:",
            "1. üåç –ï—Å–ª–∏ –ø–æ—Å—Ç –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º - –ø–µ—Ä–µ–≤–µ–¥–∏ –Ω–∞ —Ä—É—Å—Å–∫–∏–π",
            "2. üìù –ò—Å–ø–æ–ª—å–∑—É–π Telegram —Ä–∞–∑–º–µ—Ç–∫—É: **–∂–∏—Ä–Ω—ã–π**, *–∫—É—Ä—Å–∏–≤*, >—Ü–∏—Ç–∞—Ç—ã, __–ø–æ–¥—á–µ—Ä–∫–Ω—É—Ç—ã–π__, ||—Å–ø–æ–π–ª–µ—Ä||",
            "3. üé® –î–æ–±–∞–≤—å –ø–æ–¥—Ö–æ–¥—è—â–∏–µ —ç–º–æ–¥–∑–∏",
            "4. üíé –°–æ—Ö—Ä–∞–Ω–∏ –≤—Å—é –∫–ª—é—á–µ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é",
            "5. ‚ö° –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–π —Ç–µ–∫—Å—Ç –¥–ª—è –ª—É—á—à–µ–≥–æ –≤–æ—Å–ø—Ä–∏—è—Ç–∏—è",
            "",
            f"–ò–°–•–û–î–ù–´–ô –¢–ï–ö–°–¢: {original_text}",
            ""
        ])
        
        if category:
            prompt_parts.append(f"–ö–ê–¢–ï–ì–û–†–ò–Ø: {category}")
            prompt_parts.append("")
        
        prompt_parts.extend([
            "–û–¢–í–ï–¢ –í –§–û–†–ú–ê–¢–ï:",
            "–ö–ê–¢–ï–ì–û–†–ò–Ø: [crypto/macro/web3/telegram/gamefi/general]",
            "–°–¢–ò–õ–ò–ó–û–í–ê–ù–ù–´–ô –ü–û–°–¢:",
            "[–ø–µ—Ä–µ–¥–µ–ª–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç —Å HTML —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º –∏ —ç–º–æ–¥–∑–∏]"
        ])
        
        return "\n".join(prompt_parts)
    
    def _parse_stylization_response(self, response_text: str) -> Dict[str, Any]:
        """–ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞ —Å—Ç–∏–ª–∏–∑–∞—Ü–∏–∏"""
        try:
            lines = response_text.strip().split('\n')
            
            result = {
                "success": True,
                "stylized_text": "",
                "category": "general",
                "raw_response": response_text
            }
            
            stylized_text_lines = []
            collecting_stylized_text = False
            
            for line in lines:
                line = line.strip()
                
                # –ü–∞—Ä—Å–∏–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é
                if line.startswith("–ö–ê–¢–ï–ì–û–†–ò–Ø:"):
                    try:
                        category_text = line.split(":", 1)[1].strip().lower()
                        valid_categories = ["crypto", "macro", "web3", "telegram", "gamefi", "general"]
                        if any(cat in category_text for cat in valid_categories):
                            result["category"] = next(cat for cat in valid_categories if cat in category_text)
                    except:
                        logger.debug("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –∫–∞—Ç–µ–≥–æ—Ä–∏—é –∏–∑: {}", line)
                
                # –ù–∞—á–∏–Ω–∞–µ–º —Å–æ–±–∏—Ä–∞—Ç—å —Å—Ç–∏–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
                elif line.startswith("–°–¢–ò–õ–ò–ó–û–í–ê–ù–ù–´–ô –ü–û–°–¢:"):
                    collecting_stylized_text = True
                elif collecting_stylized_text and line:
                    stylized_text_lines.append(line)
            
            # –°–æ–±–∏—Ä–∞–µ–º —Å—Ç–∏–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
            if stylized_text_lines:
                result["stylized_text"] = "\n".join(stylized_text_lines).strip()
            else:
                # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å, –±–µ—Ä–µ–º –≤–µ—Å—å –æ—Ç–≤–µ—Ç –∫–∞–∫ —Å—Ç–∏–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
                result["stylized_text"] = response_text.strip()
            
            return result
            
        except Exception as e:
            logger.error("–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å—Ç–∏–ª–∏–∑–∞—Ü–∏–∏: {}", str(e))
            return {
                "success": False,
                "stylized_text": response_text or "–û—à–∏–±–∫–∞ —Å—Ç–∏–ª–∏–∑–∞—Ü–∏–∏",
                "category": "general",
                "error": str(e),
                "raw_response": response_text
            }
    
    def _build_analysis_prompt(
        self, 
        text: str, 
        image_description: Optional[str], 
        user_examples: Optional[List[str]]
    ) -> str:
        """–ü–æ—Å—Ç—Ä–æ–∏—Ç—å –ø—Ä–æ–º–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å–æ–≥–ª–∞—Å–Ω–æ –¢–ó"""
        
        # –ë–∞–∑–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç —Å–æ–≥–ª–∞—Å–Ω–æ TECHNICAL_SPECIFICATION.md
        prompt_parts = [
            "–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Å—Ç–∞–π–ª–∏–Ω–≥—É Telegram –ø–æ—Å—Ç–æ–≤ –≤ —Å—Ñ–µ—Ä–µ –∫—Ä–∏–ø—Ç–æ/–º–∞–∫—Ä–æ—ç–∫–æ–Ω–æ–º–∏–∫–∏.",
            ""
        ]
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–∏–º–µ—Ä—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –µ—Å–ª–∏ –µ—Å—Ç—å
        if user_examples:
            prompt_parts.extend([
                "–ü–†–ò–ú–ï–†–´ –ú–û–ï–ì–û –°–¢–ò–õ–Ø:",
                *[f"–ü—Ä–∏–º–µ—Ä {i+1}: {example}" for i, example in enumerate(user_examples[:3])],
                ""
            ])
        
        # –ó–∞–¥–∞—á–∞ —É–Ω–∏–∫–∞–ª–∏–∑–∞—Ü–∏–∏ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        prompt_parts.extend([
            "–ó–ê–î–ê–ß–ê: –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –ø–æ—Å—Ç –∏ –£–ù–ò–ö–ê–õ–ò–ó–ò–†–£–ô –µ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç, —Å–æ—Ö—Ä–∞–Ω–∏–≤ –°–¢–†–£–ö–¢–£–†–£ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è!",
            "",
            "üìù –ö–ê–ö –£–ù–ò–ö–ê–õ–ò–ó–ò–†–û–í–ê–¢–¨:",
            "‚Ä¢ –ü–µ—Ä–µ–ø–∏—à–∏ —Ñ—Ä–∞–∑—ã —Å–≤–æ–∏–º–∏ —Å–ª–æ–≤–∞–º–∏ (—Å–æ—Ö—Ä–∞–Ω–∏ —Å–º—ã—Å–ª)",
            "‚Ä¢ –ò–∑–º–µ–Ω–∏ –ø–æ—Ä—è–¥–æ–∫ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –≥–¥–µ –≤–æ–∑–º–æ–∂–Ω–æ", 
            "‚Ä¢ –î–æ–±–∞–≤—å/–∑–∞–º–µ–Ω–∏ –ø–æ–¥—Ö–æ–¥—è—â–∏–µ —ç–º–æ–¥–∑–∏",
            "‚Ä¢ –ò—Å–ø–æ–ª—å–∑—É–π —Å–∏–Ω–æ–Ω–∏–º—ã –∏ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è",
            "",
            "üé® –°–¢–†–û–ì–ò–ï –ü–†–ê–í–ò–õ–ê TELEGRAM –§–û–†–ú–ê–¢–ò–†–û–í–ê–ù–ò–Ø:",
            "‚Ä¢ **—Ç–µ–∫—Å—Ç** –¥–ª—è –∂–∏—Ä–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞",
            "‚Ä¢ *—Ç–µ–∫—Å—Ç* –¥–ª—è –∫—É—Ä—Å–∏–≤–∞", 
            "‚Ä¢ >—Ç–µ–∫—Å—Ç –¥–ª—è —Ü–∏—Ç–∞—Ç (–≤ –Ω–∞—á–∞–ª–µ —Å—Ç—Ä–æ–∫–∏)",
            "‚Ä¢ __—Ç–µ–∫—Å—Ç__ –¥–ª—è –ø–æ–¥—á–µ—Ä–∫–Ω—É—Ç–æ–≥–æ",
            "‚Ä¢ ||—Ç–µ–∫—Å—Ç|| –¥–ª—è —Å–ø–æ–π–ª–µ—Ä–æ–≤",
            "‚Ä¢ –ü–†–ò–ú–ï–† –ü–†–ê–í–ò–õ–¨–ù–û: **Bitcoin —Ä–∞—Å—Ç–µ—Ç**, *–∞–Ω–∞–ª–∏–∑ —Ä—ã–Ω–∫–∞*, >–≤–∞–∂–Ω–∞—è —Ü–∏—Ç–∞—Ç–∞",
            "‚Ä¢ –ù–ò–ö–ê–ö–ò–• HTML –¢–ï–ì–û–í! –¢–æ–ª—å–∫–æ Telegram —Ä–∞–∑–º–µ—Ç–∫–∞!",
            "",
            "üö´ –ß–¢–û –ö–ê–¢–ï–ì–û–†–ò–ß–ï–°–ö–ò –ó–ê–ü–†–ï–©–ï–ù–û:",
            "‚Ä¢ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å HTML —Ç–µ–≥–∏ (<b>, <strong>, <i>, –∏ —Ç.–¥.)",
            "‚Ä¢ –°–æ–∑–¥–∞–≤–∞—Ç—å –±–∏—Ç—É—é —Ä–∞–∑–º–µ—Ç–∫—É (–Ω–µ–∑–∞–∫—Ä—ã—Ç—ã–µ ** –∏–ª–∏ *)",
            "‚Ä¢ –°–º–µ—à–∏–≤–∞—Ç—å —Ä–∞–∑–Ω—ã–µ —Ç–∏–ø—ã —Ä–∞–∑–º–µ—Ç–∫–∏ –≤ –æ–¥–Ω–æ–º —Ñ—Ä–∞–≥–º–µ–Ω—Ç–µ",
            "‚Ä¢ –ü—É—Å—Ç—ã–µ —Ç–µ–≥–∏ —Ä–∞–∑–º–µ—Ç–∫–∏ (****, ****, –∏ —Ç.–¥.)",
            "",
            "üåç –ü–ï–†–ï–í–û–î: –ï—Å–ª–∏ –ø–æ—Å—Ç –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º - –ø–µ—Ä–µ–≤–µ–¥–∏ –Ω–∞ —Ä—É—Å—Å–∫–∏–π, —Å–æ—Ö—Ä–∞–Ω–∏–≤ —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è!",
            "–ü–µ—Ä–µ–≤–æ–¥–∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ (mining‚Üí–º–∞–π–Ω–∏–Ω–≥, staking‚Üí—Å—Ç–µ–π–∫–∏–Ω–≥, yield‚Üí–¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å).",
            "–°–æ—Ö—Ä–∞–Ω—è–π –Ω–∞–∑–≤–∞–Ω–∏—è –ø—Ä–æ–µ–∫—Ç–æ–≤ –∏ —Ç–∏–∫–µ—Ä—ã –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª–µ (Bitcoin, Ethereum, BTC, ETH).",
            "",
            "–ö–†–ò–¢–ï–†–ò–ò –†–ï–õ–ï–í–ê–ù–¢–ù–û–°–¢–ò (1-10 –±–∞–ª–ª–æ–≤):",
            "- –ö—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç—ã (Bitcoin, Ethereum, –∞–ª—å—Ç–∫–æ–∏–Ω—ã, DeFi)",
            "- –ú–∞–∫—Ä–æ—ç–∫–æ–Ω–æ–º–∏–∫–∞ (–§–†–°, –∏–Ω—Ñ–ª—è—Ü–∏—è, —ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏)",
            "- Web3 (–±–ª–æ–∫—á–µ–π–Ω, NFT, –º–µ—Ç–∞–≤—Å–µ–ª–µ–Ω–Ω—ã–µ)",
            "- Telegram (–Ω–æ–≤–æ—Å—Ç–∏ –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã)",
            "- GameFi (–±–ª–æ–∫—á–µ–π–Ω –∏–≥—Ä—ã, play-to-earn)",
            "",
            f"–û–†–ò–ì–ò–ù–ê–õ–¨–ù–´–ô –ü–û–°–¢: {text}",
        ])
        
        # –î–æ–±–∞–≤–ª—è–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –µ—Å–ª–∏ –µ—Å—Ç—å
        if image_description:
            prompt_parts.append(f"–û–ü–ò–°–ê–ù–ò–ï –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–Ø: {image_description}")
        
        prompt_parts.extend([
            "",
            "üîç –§–ò–ù–ê–õ–¨–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê TELEGRAM –†–ê–ó–ú–ï–¢–ö–ò –ü–ï–†–ï–î –û–¢–í–ï–¢–û–ú:",
            "‚Ä¢ –ü—Ä–æ–≤–µ—Ä—å –∫–∞–∂–¥—ã–π **—Ç–µ–∫—Å—Ç** - –ø—Ä–∞–≤–∏–ª—å–Ω–æ –ª–∏ –∑–∞–∫—Ä—ã—Ç?",
            "‚Ä¢ –ü—Ä–æ–≤–µ—Ä—å –∫–∞–∂–¥—ã–π *—Ç–µ–∫—Å—Ç* - –Ω–µ—Ç –ª–∏ –Ω–µ–∑–∞–∫—Ä—ã—Ç—ã—Ö?", 
            "‚Ä¢ –ü—Ä–æ–≤–µ—Ä—å –∫–∞–∂–¥—É—é —Ü–∏—Ç–∞—Ç—É >—Ç–µ–∫—Å—Ç - –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å –Ω–∞—á–∞–ª–∞ —Å—Ç—Ä–æ–∫–∏?",
            "‚Ä¢ –ù–ï–¢ –ª–∏ –±–∏—Ç—ã—Ö –∫–æ–º–±–∏–Ω–∞—Ü–∏–π —Ç–∏–ø–∞ ***, ****, |||| ?",
            "‚Ä¢ –ù–ò–ö–ê–ö–ò–• HTML —Ç–µ–≥–æ–≤ –≤ —Ç–µ–∫—Å—Ç–µ?",
            "‚Ä¢ –í–°–Ø —Ä–∞–∑–º–µ—Ç–∫–∞ –≤ Telegram —Ñ–æ—Ä–º–∞—Ç–µ?",
            "",
            "–û–¢–í–ï–¢–¨ –°–¢–†–û–ì–û –í –§–û–†–ú–ê–¢–ï:",
            "–†–ï–õ–ï–í–ê–ù–¢–ù–û–°–¢–¨: [—á–∏—Å–ª–æ –æ—Ç 1 –¥–æ 10]",
            "–¢–û–ù–ê–õ–¨–ù–û–°–¢–¨: [–ø–æ–∑–∏—Ç–∏–≤–Ω–∞—è/–Ω–µ–≥–∞—Ç–∏–≤–Ω–∞—è/–Ω–µ–π—Ç—Ä–∞–ª—å–Ω–∞—è]", 
            "–£–ù–ò–ö–ê–õ–ò–ó–ò–†–û–í–ê–ù–ù–´–ô –ü–û–°–¢:",
            "[–ø–µ—Ä–µ–ø–∏—Å–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç —Å TELEGRAM —Ä–∞–∑–º–µ—Ç–∫–æ–π - **–∂–∏—Ä–Ω—ã–π**, *–∫—É—Ä—Å–∏–≤*, >—Ü–∏—Ç–∞—Ç—ã, __–ø–æ–¥—á–µ—Ä–∫–Ω—É—Ç—ã–π__, ||—Å–ø–æ–π–ª–µ—Ä||]"
        ])
        
        return "\n".join(prompt_parts)
    
    def _build_uniqualization_prompt(
        self,
        original_text: str,
        user_examples: List[str],
        source_channel_title: Optional[str] = None,
        source_channel_username: Optional[str] = None
    ) -> str:
        """–°–æ–∑–¥–∞—Ç—å –ø—Ä–æ–º–ø—Ç –¥–ª—è –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –ø–æ–¥ —Å—Ç–∏–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""

        prompt_parts = [
            "üéØ –ó–ê–î–ê–ß–ê: –ê–î–ê–ü–¢–ò–†–û–í–ê–¢–¨ –ü–û–°–¢ –ü–û–î –ú–û–ô –°–¢–ò–õ–¨",
            "",
            "–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –≤ –∫—Ä–∏–ø—Ç–æ/–º–∞–∫—Ä–æ—ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–æ–π —Å—Ñ–µ—Ä–µ.",
            "–¢–≤–æ—è –∑–∞–¥–∞—á–∞ - –ø–µ—Ä–µ–ø–∏—Å–∞—Ç—å –ø–æ—Å—Ç –í –ú–û–Å–ú –°–¢–ò–õ–ï, –∏—Å–ø–æ–ª—å–∑—É—è –º–æ–∏ –ø—Ä–∏–º–µ—Ä—ã –∫–∞–∫ –æ–±—Ä–∞–∑–µ—Ü.",
            "",
        ]

        # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–∏–º–µ—Ä—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –ë–ï–ó –õ–ò–ú–ò–¢–ê –î–õ–ò–ù–´
        if user_examples:
            prompt_parts.extend([
                "=" * 50,
                "üìù –ú–û–ò –ü–û–°–¢–´ - –û–ë–†–ê–ó–¶–´ –°–¢–ò–õ–Ø (–∏–∑—É—á–∏ –≤–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ!):",
                "=" * 50,
                "",
            ])

            for i, example in enumerate(user_examples, 1):
                prompt_parts.extend([
                    f"--- –ü–†–ò–ú–ï–† {i} ---",
                    example,  # –ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –±–µ–∑ –æ–±—Ä–µ–∑–∫–∏!
                    "",
                ])

            prompt_parts.extend([
                "=" * 50,
                "",
                "üîç –ê–ù–ê–õ–ò–ó –ú–û–ï–ì–û –°–¢–ò–õ–Ø (—á—Ç–æ –Ω—É–∂–Ω–æ –ø–µ—Ä–µ–Ω—è—Ç—å):",
                "‚Ä¢ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø–æ—Å—Ç–æ–≤ (–∫–∞–∫ –Ω–∞—á–∏–Ω–∞—é, –∫–∞–∫ –∑–∞–∫–∞–Ω—á–∏–≤–∞—é)",
                "‚Ä¢ –¢–æ–Ω –∏ –ø–æ–¥–∞—á–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏",
                "‚Ä¢ –ö–∞–∫ –∏—Å–ø–æ–ª—å–∑—É—é —ç–º–æ–¥–∑–∏ –∏ –≥–¥–µ –∏—Ö —Å—Ç–∞–≤–ª—é",
                "‚Ä¢ –î–ª–∏–Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –∏ –∞–±–∑–∞—Ü–µ–≤",
                "‚Ä¢ –ö–∞–∫ –≤—ã–¥–µ–ª—è—é –∫–ª—é—á–µ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é",
                "",
            ])

        # –î–æ–±–∞–≤–ª—è–µ–º —Å–µ–∫—Ü–∏—é —Å —Ä–∞–∑—Ä–µ—à–µ–Ω–Ω—ã–º–∏ —ç–º–æ–¥–∑–∏
        prompt_parts.append(get_emoji_prompt_section())

        prompt_parts.extend([
            "üìã –ü–†–ê–í–ò–õ–ê –ê–î–ê–ü–¢–ê–¶–ò–ò:",
            "‚Ä¢ –ü–µ—Ä–µ–ø–∏—à–∏ –ø–æ—Å—Ç –ü–û–õ–ù–û–°–¢–¨–Æ –≤ –º–æ—ë–º —Å—Ç–∏–ª–µ",
            "‚Ä¢ –ò—Å–ø–æ–ª—å–∑—É–π –º–æ—é –º–∞–Ω–µ—Ä—É –ø–æ–¥–∞—á–∏ –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—É",
            "‚Ä¢ –°–æ—Ö—Ä–∞–Ω–∏ –í–°–ï —Ñ–∞–∫—Ç—ã, —Ü–∏—Ñ—Ä—ã, –¥–∞—Ç—ã, –Ω–∞–∑–≤–∞–Ω–∏—è",
            "‚Ä¢ –ù–ï –¥–æ–±–∞–≤–ª—è–π —Å–≤–æ–∏ –º—ã—Å–ª–∏ - —Ç–æ–ª—å–∫–æ –∞–¥–∞–ø—Ç–∏—Ä—É–π —Ñ–æ—Ä–º—É",
            "",
            "üö´ –£–î–ê–õ–ò–¢–¨ –ë–†–ï–ù–î–ò–ù–ì –ß–£–ñ–û–ì–û –ö–ê–ù–ê–õ–ê:",
        ])

        # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –∏—Å—Ç–æ—á–Ω–∏–∫–µ –µ—Å–ª–∏ –∏–∑–≤–µ—Å—Ç–Ω–∞
        if source_channel_username:
            prompt_parts.append(f"‚Ä¢ –£–ø–æ–º–∏–Ω–∞–Ω–∏–µ @{source_channel_username} –∏ –ø–æ—Ö–æ–∂–∏–µ @—É–ø–æ–º–∏–Ω–∞–Ω–∏—è")
        else:
            prompt_parts.append("‚Ä¢ –í–°–ï @—É–ø–æ–º–∏–Ω–∞–Ω–∏—è –∫–∞–Ω–∞–ª–æ–≤ (@channel_name, @username)")

        if source_channel_title:
            prompt_parts.append(f"‚Ä¢ –ù–∞–∑–≤–∞–Ω–∏–µ –∫–∞–Ω–∞–ª–∞ ¬´{source_channel_title}¬ª –µ—Å–ª–∏ –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è –≤ —Ç–µ–∫—Å—Ç–µ")

        prompt_parts.extend([
            "‚Ä¢ –†–µ–∫–ª–∞–º–Ω—ã–µ –ø—Ä–∏–∑—ã–≤—ã ('–ø–æ–¥–ø–∏—Å—ã–≤–∞–π—Ç–µ—Å—å', '—á–∏—Ç–∞–π—Ç–µ –Ω–∞—Å', '–Ω–∞—à –∫–∞–Ω–∞–ª')",
            "‚Ä¢ –ü–æ–¥–ø–∏—Å–∏ —Ç–∏–ø–∞ '–ò—Å—Ç–æ—á–Ω–∏–∫:', '–í–∑—è—Ç–æ –∏–∑:', '–ß–∏—Ç–∞—Ç—å –¥–∞–ª–µ–µ –≤...'",
            "‚Ä¢ –§–£–¢–ï–†–´/–ü–û–î–ü–ò–°–ò –∫–∞–Ω–∞–ª–æ–≤ –≤ –∫–æ–Ω—Ü–µ –ø–æ—Å—Ç–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä: '‚úÖ –ù–æ–≤–æ—Å—Ç–∏ ‚úÖ –†—ã–Ω–∫–∏ ‚úÖ YouTube')",
            "‚Ä¢ –ù–∞–≤–∏–≥–∞—Ü–∏–æ–Ω–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã —Ç–∏–ø–∞: '–ù–æ–≤–æ—Å—Ç–∏ | –†—ã–Ω–∫–∏ | –û–±–∑–æ—Ä—ã | YouTube'",
            "‚Ä¢ –õ—é–±—ã–µ —Å–ø–∏—Å–∫–∏ —Ä–∞–∑–¥–µ–ª–æ–≤ –∫–∞–Ω–∞–ª–∞ –≤ –∫–æ–Ω—Ü–µ –ø–æ—Å—Ç–∞",
            "",
            "üîó –°–°–´–õ–ö–ò –ù–ê –ò–°–¢–û–ß–ù–ò–ö - –í–ê–ñ–ù–û!",
            "‚Ä¢ –ü–û–õ–ù–û–°–¢–¨–Æ –£–î–ê–õ–ò –ª—é–±—ã–µ —Å—Ç—Ä–æ–∫–∏ —Å URL –≤ –∫–æ–Ω—Ü–µ –ø–æ—Å—Ç–∞!",
            "‚Ä¢ –£–¥–∞–ª–∏: '–ò—Å—Ç–æ—á–Ω–∏–∫: URL', '–ü–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏: URL', '–ß–∏—Ç–∞—Ç—å: URL', '–î–µ—Ç–∞–ª–∏: URL'",
            "‚Ä¢ –£–¥–∞–ª–∏: 'üîó –ü–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏: URL', 'üîç –ò—Å—Ç–æ—á–Ω–∏–∫: URL', 'üìé –°—Å—ã–ª–∫–∞: URL'",
            "‚Ä¢ –£–¥–∞–ª–∏: –≥–æ–ª—ã–µ URL –±–µ–∑ —Ç–µ–∫—Å—Ç–∞ (https://... –≤ –∫–æ–Ω—Ü–µ –ø–æ—Å—Ç–∞)",
            "‚Ä¢ –°—Å—ã–ª–∫–∞ –±—É–¥–µ—Ç –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–ò –≤—Å—Ç—Ä–æ–µ–Ω–∞ –≤ –≥–ª–∞–≥–æ–ª –Ω–∞ —Å–ª–µ–¥—É—é—â–µ–º —ç—Ç–∞–ø–µ!",
            "‚Ä¢ –ï—Å–ª–∏ URL –µ—Å—Ç—å –≤–Ω—É—Ç—Ä–∏ —Ç–µ–∫—Å—Ç–∞ –∫–∞–∫ —á–∞—Å—Ç—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è - –¢–û–ñ–ï –£–î–ê–õ–ò!",
            "‚Ä¢ –£–ë–ï–†–ò –∑–∞–≥–æ–ª–æ–≤–∫–∏ —Ç–∏–ø–∞: '–í–ê–ñ–ù–´–ï –ù–û–í–û–°–¢–ò', '–ê–ö–¢–£–ê–õ–¨–ù–´–ï –ù–û–í–û–°–¢–ò', '–°–†–û–ß–ù–û', 'BREAKING', 'NEWS'!",
            "‚Ä¢ –î–∞–∂–µ –µ—Å–ª–∏ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª–µ –µ—Å—Ç—å —Ç–∞–∫–æ–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ - –£–î–ê–õ–ò –µ–≥–æ!",
            "‚Ä¢ –ù–∞—á–∏–Ω–∞–π —Å—Ä–∞–∑—É —Å —Å—É—Ç–∏ –Ω–æ–≤–æ—Å—Ç–∏, –±–µ–∑ –≤–≤–æ–¥–Ω—ã—Ö –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤",
            "",
            "üí¨ –¶–ò–¢–ê–¢–´:",
            "‚Ä¢ –¶–∏—Ç–∞—Ç—ã (—Ç–µ–∫—Å—Ç –≤ –∫–∞–≤—ã—á–∫–∞—Ö) —Å–æ—Ö—Ä–∞–Ω—è–π –î–û–°–õ–û–í–ù–û!",
            "‚Ä¢ –ù–µ —É–Ω–∏–∫–∞–ª–∏–∑–∏—Ä—É–π –∏ –Ω–µ –ø–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä—É–π —Ü–∏—Ç–∞—Ç—ã - –æ–Ω–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Ç–æ—á–Ω—ã–º–∏",
            "‚Ä¢ –ï—Å–ª–∏ —Ü–∏—Ç–∞—Ç–∞ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º - –ø–µ—Ä–µ–≤–µ–¥–∏ –µ—ë –¥–æ—Å–ª–æ–≤–Ω–æ –Ω–∞ —Ä—É—Å—Å–∫–∏–π",
            "‚Ä¢ –ü—Ä–∏–º–µ—Ä: 'Bitcoin is the future' ‚Üí '–ë–∏—Ç–∫–æ–∏–Ω - —ç—Ç–æ –±—É–¥—É—â–µ–µ'",
            "",
            "üö® –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û –ü–û –≠–ú–û–î–ó–ò:",
            "‚Ä¢ –≠–º–æ–¥–∑–∏ –¢–û–õ–¨–ö–û –∏–∑ —Ä–∞–∑—Ä–µ—à—ë–Ω–Ω–æ–≥–æ —Å–ø–∏—Å–∫–∞ –≤—ã—à–µ!",
            "‚Ä¢ –£–î–ê–õ–ò –∏–ª–∏ –ó–ê–ú–ï–ù–ò –≤—Å–µ —ç–º–æ–¥–∑–∏ –∏–∑ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –ø–æ—Å—Ç–∞ –∫–æ—Ç–æ—Ä—ã—Ö –ù–ï–¢ –≤ —Å–ø–∏—Å–∫–µ!",
            "‚Ä¢ –ü—Ä–∏–º–µ—Ä—ã –∑–∞–º–µ–Ω—ã: üîµ‚Üí‚úÖ, üü°‚Üí‚ö†Ô∏è, üê¶‚Üíüì∞, üöÄ‚Üí‚¨ÜÔ∏è, üíé‚Üíü™ô, üìà‚Üí‚¨ÜÔ∏è, üìâ‚Üí‚¨áÔ∏è",
            "‚Ä¢ –ï—Å–ª–∏ –Ω–µ –∑–Ω–∞–µ—à—å –Ω–∞ —á—Ç–æ –∑–∞–º–µ–Ω–∏—Ç—å - –£–î–ê–õ–ò —ç–º–æ–¥–∑–∏ –ø–æ–ª–Ω–æ—Å—Ç—å—é!",
            "‚Ä¢ –ù–ï –ö–û–ü–ò–†–£–ô —ç–º–æ–¥–∑–∏ –∏–∑ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –ø–æ—Å—Ç–∞ –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç –≤ —Å–ø–∏—Å–∫–µ!",
            "",
            "‚ö†Ô∏è –§–û–†–ú–ê–¢–ò–†–û–í–ê–ù–ò–ï –ù–ê –≠–¢–û–ú –≠–¢–ê–ü–ï:",
            "‚Ä¢ –í–µ—Ä–Ω–∏ –ß–ò–°–¢–´–ô —Ç–µ–∫—Å—Ç –ë–ï–ó HTML —Ç–µ–≥–æ–≤",
            "‚Ä¢ HTML –±—É–¥–µ—Ç –¥–æ–±–∞–≤–ª–µ–Ω –Ω–∞ —Å–ª–µ–¥—É—é—â–µ–º —ç—Ç–∞–ø–µ",
            "‚Ä¢ –≠–º–æ–¥–∑–∏ –¢–û–õ–¨–ö–û –∏–∑ —Ä–∞–∑—Ä–µ—à—ë–Ω–Ω–æ–≥–æ —Å–ø–∏—Å–∫–∞ - –î–ê",
            "‚Ä¢ HTML —Ç–µ–≥–∏ (<b>, <i>, <strong>) - –ù–ï–¢!",
            "",
            "üåç –ï–°–õ–ò –ü–û–°–¢ –ù–ê –ê–ù–ì–õ–ò–ô–°–ö–û–ú:",
            "‚Ä¢ –ü–µ—Ä–µ–≤–µ–¥–∏ –Ω–∞ —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫",
            "‚Ä¢ –ù–∞–∑–≤–∞–Ω–∏—è –ø—Ä–æ–µ–∫—Ç–æ–≤/–∫–æ–º–ø–∞–Ω–∏–π –æ—Å—Ç–∞–≤—å –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º (Bitcoin, Ethereum, Binance)",
            "‚Ä¢ –¢–∏–∫–µ—Ä—ã –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º (BTC, ETH, SOL)",
            "‚Ä¢ –¢–µ—Ä–º–∏–Ω—ã –ø–µ—Ä–µ–≤–æ–¥–∏: staking‚Üí—Å—Ç–µ–π–∫–∏–Ω–≥, mining‚Üí–º–∞–π–Ω–∏–Ω–≥, yield‚Üí–¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å",
            "",
            "=" * 50,
            "üìÑ –ò–°–•–û–î–ù–´–ô –ü–û–°–¢ –î–õ–Ø –ê–î–ê–ü–¢–ê–¶–ò–ò:",
            "=" * 50,
            "",
            original_text,
            "",
            "=" * 50,
            "",
            "üéØ –†–ï–ó–£–õ–¨–¢–ê–¢:",
            "‚Ä¢ –ü–æ—Å—Ç –≤ –ú–û–Å–ú —Å—Ç–∏–ª–µ (–∫–∞–∫ –≤ –ø—Ä–∏–º–µ—Ä–∞—Ö –≤—ã—à–µ)",
            "‚Ä¢ –≠–º–æ–¥–∑–∏ –¢–û–õ–¨–ö–û –∏–∑ —Ä–∞–∑—Ä–µ—à–µ–Ω–Ω–æ–≥–æ —Å–ø–∏—Å–∫–∞",
            "‚Ä¢ –ß–∏—Å—Ç—ã–π —Ç–µ–∫—Å—Ç –ë–ï–ó HTML",
            "‚Ä¢ –í—Å–µ —Ñ–∞–∫—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã",
            "",
            "–û–¢–í–ï–¢–¨ –¢–û–õ–¨–ö–û –ê–î–ê–ü–¢–ò–†–û–í–ê–ù–ù–´–ú –¢–ï–ö–°–¢–û–ú –ë–ï–ó –ö–û–ú–ú–ï–ù–¢–ê–†–ò–ï–í!"
        ])

        return "\n".join(prompt_parts)
    
    def _build_markdown_formatting_prompt(self, text: str) -> str:
        """–°–æ–∑–¥–∞—Ç—å –ø—Ä–æ–º–ø—Ç –¥–ª—è Markdown —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (–¥–ª—è Telethon)"""

        prompt_parts = [
            "–ó–ê–î–ê–ß–ê: –î–æ–±–∞–≤—å Markdown —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫ —Ç–µ–∫—Å—Ç—É.",
            "",
            "–°–ò–ù–¢–ê–ö–°–ò–°:",
            "‚Ä¢ **–∂–∏—Ä–Ω—ã–π —Ç–µ–∫—Å—Ç** - –¥–ª—è –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –∏ –∫–ª—é—á–µ–≤—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤",
            "‚Ä¢ __–∫—É—Ä—Å–∏–≤__ - –¥–ª—è –∞–∫—Ü–µ–Ω—Ç–æ–≤ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)",
            "",
            "–ü–†–ê–í–ò–õ–ê:",
            "1. –ù–ï –ú–ï–ù–Ø–ô —Ç–µ–∫—Å—Ç - —Ç–æ–ª—å–∫–æ –¥–æ–±–∞–≤–ª—è–π —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ",
            "2. –ù–ï –ú–ï–ù–Ø–ô —ç–º–æ–¥–∑–∏ - –æ–Ω–∏ –¥–æ–ª–∂–Ω—ã –æ—Å—Ç–∞—Ç—å—Å—è –¢–û–ß–ù–û –∫–∞–∫ –µ—Å—Ç—å",
            "3. –ö–∞–∂–¥—ã–π ** –¥–æ–ª–∂–µ–Ω –∏–º–µ—Ç—å –∑–∞–∫—Ä—ã–≤–∞—é—â–∏–π **",
            "4. –ö–∞–∂–¥—ã–π __ –¥–æ–ª–∂–µ–Ω –∏–º–µ—Ç—å –∑–∞–∫—Ä—ã–≤–∞—é—â–∏–π __",
            "",
            "‚ö†Ô∏è –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û:",
            "‚Ä¢ –û—Ç–≤–µ—Ç—å –¢–û–õ–¨–ö–û –æ—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º",
            "‚Ä¢ –ù–ï –¥–æ–±–∞–≤–ª—è–π –ø–æ—è—Å–Ω–µ–Ω–∏—è, –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –∏–ª–∏ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏",
            "‚Ä¢ –ù–ï –ø–∏—à–∏ '–í–æ—Ç —Ç–µ–∫—Å—Ç:', '–ì–æ—Ç–æ–≤–æ:', –∏ —Ç.–ø.",
            "‚Ä¢ –ù–ï –≤–∫–ª—é—á–∞–π —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏ --- –≤ –æ—Ç–≤–µ—Ç!",
            "‚Ä¢ –¢–û–õ–¨–ö–û —Ç–µ–∫—Å—Ç —Å Markdown —Ä–∞–∑–º–µ—Ç–∫–æ–π - –±–æ–ª—å—à–µ –ù–ò–ß–ï–ì–û!",
            "",
            "–¢–ï–ö–°–¢ –î–õ–Ø –§–û–†–ú–ê–¢–ò–†–û–í–ê–ù–ò–Ø:",
            "<<<",
            text,
            ">>>",
            "",
            "–û–¢–í–ï–¢ (—Ç–æ–ª—å–∫–æ –æ—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç, –±–µ–∑ <<< –∏ >>>):"
        ]

        return "\n".join(prompt_parts)
    
    def _parse_uniqualization_response(self, response_text: str) -> Dict[str, Any]:
        """–ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞ —É–Ω–∏–∫–∞–ª–∏–∑–∞—Ü–∏–∏"""
        try:
            # –û—á–∏—â–∞–µ–º –æ—Ç HTML —Ç–µ–≥–æ–≤ –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π (–µ—Å–ª–∏ –ò–ò –Ω–µ –ø–æ—Å–ª—É—à–∞–ª—Å—è)
            clean_text = self._strip_html_tags(response_text.strip())

            return {
                "success": True,
                "uniqualized_text": clean_text,
                "raw_response": response_text
            }
        except Exception as e:
            logger.error("–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —É–Ω–∏–∫–∞–ª–∏–∑–∞—Ü–∏–∏: {}", str(e))
            return {
                "success": False,
                "uniqualized_text": response_text or "–û—à–∏–±–∫–∞ —É–Ω–∏–∫–∞–ª–∏–∑–∞—Ü–∏–∏",
                "error": str(e)
            }
    
    def _strip_html_tags(self, text: str) -> str:
        """–£–±—Ä–∞—Ç—å HTML —Ç–µ–≥–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞ (–¥–ª—è —ç—Ç–∞–ø–∞ 1), –°–û–•–†–ê–ù–Ø–Ø –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫"""
        try:
            import re
            # –£–±–∏—Ä–∞–µ–º –≤—Å–µ HTML —Ç–µ–≥–∏
            clean_text = re.sub(r'<[^>]+>', '', text)
            # –£–±–∏—Ä–∞–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ü–†–û–ë–ï–õ–´ (–Ω–æ –ù–ï –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫!)
            clean_text = re.sub(r'[^\S\n]+', ' ', clean_text)
            # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ (–±–æ–ª—å—à–µ 2 –ø–æ–¥—Ä—è–¥)
            clean_text = re.sub(r'\n{3,}', '\n\n', clean_text)

            logger.debug("–û—á–∏—Å—Ç–∫–∞ HTML —Ç–µ–≥–æ–≤: {} -> {} —Å–∏–º–≤–æ–ª–æ–≤", len(text), len(clean_text))
            return clean_text.strip()

        except Exception as e:
            logger.error("–û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ HTML —Ç–µ–≥–æ–≤: {}", str(e))
            return text
    
    def _clean_markdown_code_blocks(self, text: str) -> str:
        """–£–±—Ä–∞—Ç—å markdown –∫–æ–¥ –±–ª–æ–∫–∏ (```html, ```markdown –∏ —Ç.–¥.)"""
        try:
            import re
            
            # –£–±–∏—Ä–∞–µ–º markdown –±–ª–æ–∫–∏ –≤ –Ω–∞—á–∞–ª–µ
            text = re.sub(r'^```\w*\s*\n?', '', text, flags=re.MULTILINE)
            
            # –£–±–∏—Ä–∞–µ–º markdown –±–ª–æ–∫–∏ –≤ –∫–æ–Ω—Ü–µ  
            text = re.sub(r'\n?```\s*$', '', text, flags=re.MULTILINE)
            
            # –£–±–∏—Ä–∞–µ–º –æ–¥–∏–Ω–æ—á–Ω—ã–µ ``` –±–µ–∑ —è–∑—ã–∫–∞
            text = re.sub(r'^```\s*\n?', '', text, flags=re.MULTILINE)
            text = re.sub(r'\n?```\s*$', '', text, flags=re.MULTILINE)
            
            return text.strip()
            
        except Exception as e:
            logger.error("–û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ markdown –±–ª–æ–∫–æ–≤: {}", str(e))
            return text
    
    def _clean_html_for_telegram(self, text: str) -> str:
        """–û—á–∏—Å—Ç–∫–∞ HTML —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ –¥–ª—è Telegram API"""
        try:
            import re
            
            # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –ø–æ—Å–ª–µ –æ—Ç–∫—Ä—ã–≤–∞—é—â–∏—Ö –∏ –∑–∞–∫—Ä—ã–≤–∞—é—â–∏—Ö —Ç–µ–≥–æ–≤
            text = re.sub(r'<b>\s+', '<b>', text)
            text = re.sub(r'\s+</b>', '</b>', text)
            text = re.sub(r'<i>\s+', '<i>', text)
            text = re.sub(r'\s+</i>', '</i>', text)
            
            # –£–±–∏—Ä–∞–µ–º –ø—É—Å—Ç—ã–µ HTML —Ç–µ–≥–∏
            text = re.sub(r'<b>\s*</b>', '', text)
            text = re.sub(r'<i>\s*</i>', '', text)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ –∏—Å–ø—Ä–∞–≤–ª—è–µ–º –ø–∞—Ä–Ω–æ—Å—Ç—å —Ç–µ–≥–æ–≤
            text = self._ensure_html_tags_balanced(text)
            
            # –£–±–∏—Ä–∞–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã –∏ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫
            text = re.sub(r' +', ' ', text)  # –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã -> –æ–¥–∏–Ω –ø—Ä–æ–±–µ–ª
            text = re.sub(r'\n\n\n+', '\n\n', text)  # –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø–µ—Ä–µ–Ω–æ—Å—ã -> –¥–≤–∞
            
            return text.strip()
            
        except Exception as e:
            logger.error("–û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ HTML –¥–ª—è Telegram: {}", str(e))
            return text
    
    def _ensure_html_tags_balanced(self, text: str) -> str:
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∏ –∏—Å–ø—Ä–∞–≤–∏—Ç—å –±–∞–ª–∞–Ω—Å HTML —Ç–µ–≥–æ–≤"""
        try:
            import re
            
            # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–∂–¥–æ–≥–æ —Ç–∏–ø–∞ —Ç–µ–≥–æ–≤
            tag_pairs = [
                ('b', r'<b>', r'</b>'),
                ('i', r'<i>', r'</i>')
            ]
            
            for tag_name, open_pattern, close_pattern in tag_pairs:
                open_count = len(re.findall(open_pattern, text))
                close_count = len(re.findall(close_pattern, text))
                
                if open_count > close_count:
                    # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –∑–∞–∫—Ä—ã–≤–∞—é—â–∏–µ —Ç–µ–≥–∏
                    missing = open_count - close_count
                    text += f'</{tag_name}>' * missing
                    logger.debug("–î–æ–±–∞–≤–ª–µ–Ω–æ {} –∑–∞–∫—Ä—ã–≤–∞—é—â–∏—Ö —Ç–µ–≥–æ–≤ </{}>", missing, tag_name)
                    
                elif close_count > open_count:
                    # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –∑–∞–∫—Ä—ã–≤–∞—é—â–∏–µ —Ç–µ–≥–∏
                    extra = close_count - open_count
                    for _ in range(extra):
                        text = re.sub(close_pattern, '', text, count=1)
                    logger.debug("–£–¥–∞–ª–µ–Ω–æ {} –ª–∏—à–Ω–∏—Ö –∑–∞–∫—Ä—ã–≤–∞—é—â–∏—Ö —Ç–µ–≥–æ–≤ </{}>", extra, tag_name)
            
            return text
            
        except Exception as e:
            logger.error("–û—à–∏–±–∫–∞ –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏ HTML —Ç–µ–≥–æ–≤: {}", str(e))
            return text
    
    def _validate_and_fix_html(self, html_text: str) -> str:
        """–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ HTML —Ä–∞–∑–º–µ—Ç–∫–∏ –¥–ª—è Telegram"""
        try:
            if not html_text or not html_text.strip():
                return html_text
            
            logger.debug("–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ HTML —Ä–∞–∑–º–µ—Ç–∫–∏: {} —Å–∏–º–≤–æ–ª–æ–≤", len(html_text))
            
            # 1. –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ HTML –æ—à–∏–±–∫–∏
            import re
            
            # –£–±–∏—Ä–∞–µ–º –ø—É—Å—Ç—ã–µ —Ç–µ–≥–∏
            html_text = re.sub(r'<strong>\s*</strong>', '', html_text)
            html_text = re.sub(r'<i>\s*</i>', '', html_text)
            
            # 2. –£–±–∏—Ä–∞–µ–º –≤–∏—Å—è—â–∏–µ –∑–∞–∫—Ä—ã–≤–∞—é—â–∏–µ —Ç–µ–≥–∏ –≤ –Ω–∞—á–∞–ª–µ —Å—Ç—Ä–æ–∫
            lines = html_text.split('\n')
            fixed_lines = []
            
            for line in lines:
                # –£–±–∏—Ä–∞–µ–º –∑–∞–∫—Ä—ã–≤–∞—é—â–∏–µ —Ç–µ–≥–∏ —Å –Ω–∞—á–∞–ª–∞ —Å—Ç—Ä–æ–∫ (—Å–∞–º–∞—è —á–∞—Å—Ç–∞—è –ø—Ä–æ–±–ª–µ–º–∞)
                line = re.sub(r'^\s*</strong>\s*', '', line)
                line = re.sub(r'^\s*</i>\s*', '', line)
                fixed_lines.append(line)
            
            result_text = '\n'.join(fixed_lines)
            
            # 3. –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞—Ä–Ω–æ—Å—Ç—å —Ç–µ–≥–æ–≤ –∏ –∏—Å–ø—Ä–∞–≤–ª—è–µ–º
            result_text = self._fix_html_tag_pairs(result_text)
            
            logger.debug("HTML —Ä–∞–∑–º–µ—Ç–∫–∞ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∞: {} -> {} —Å–∏–º–≤–æ–ª–æ–≤", 
                        len(html_text), len(result_text))
            
            return result_text
            
        except Exception as e:
            logger.error("–û—à–∏–±–∫–∞ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è HTML: {}", str(e))
            # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
            return html_text
    
    def _fix_html_tag_pairs(self, text: str) -> str:
        """–ò—Å–ø—Ä–∞–≤–∏—Ç—å –ø–∞—Ä–Ω–æ—Å—Ç—å HTML —Ç–µ–≥–æ–≤"""
        try:
            import re
            
            # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –æ—Ç–∫—Ä—ã–≤–∞—é—â–∏–µ –∏ –∑–∞–∫—Ä—ã–≤–∞—é—â–∏–µ —Ç–µ–≥–∏
            tags_to_check = ['strong', 'i']
            
            for tag in tags_to_check:
                # –°—á–∏—Ç–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–∫—Ä—ã–≤–∞—é—â–∏—Ö –∏ –∑–∞–∫—Ä—ã–≤–∞—é—â–∏—Ö —Ç–µ–≥–æ–≤
                opening_count = len(re.findall(f'<{tag}>', text))
                closing_count = len(re.findall(f'</{tag}>', text))
                
                # –ï—Å–ª–∏ –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω—ã, –∏—Å–ø—Ä–∞–≤–ª—è–µ–º
                if opening_count > closing_count:
                    # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –∑–∞–∫—Ä—ã–≤–∞—é—â–∏–µ —Ç–µ–≥–∏ –≤ –∫–æ–Ω–µ—Ü
                    missing_closes = opening_count - closing_count
                    text += f'</{tag}>' * missing_closes
                elif closing_count > opening_count:
                    # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –∑–∞–∫—Ä—ã–≤–∞—é—â–∏–µ —Ç–µ–≥–∏
                    extra_closes = closing_count - opening_count
                    for _ in range(extra_closes):
                        text = re.sub(f'</{tag}>', '', text, count=1)
            
            return text
            
        except Exception as e:
            logger.error("–û—à–∏–±–∫–∞ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø–∞—Ä–Ω–æ—Å—Ç–∏ —Ç–µ–≥–æ–≤: {}", str(e))
            return text
    
    def _validate_and_fix_telegram_markup(self, text: str) -> str:
        """–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ Telegram —Ä–∞–∑–º–µ—Ç–∫–∏ –æ—Ç AI - —Ç–æ–ª—å–∫–æ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏"""
        try:
            if not text or not text.strip():
                return text
            
            logger.debug("–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ Telegram —Ä–∞–∑–º–µ—Ç–∫–∏: {} —Å–∏–º–≤–æ–ª–æ–≤", len(text))
            
            # 1. –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º HTML —Ç–µ–≥–∏ –≤ Telegram —Ä–∞–∑–º–µ—Ç–∫—É (–µ—Å–ª–∏ AI –≤—Å—ë-—Ç–∞–∫–∏ –∏—Ö –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª)
            text = text.replace('<strong>', '**')
            text = text.replace('</strong>', '**')
            text = text.replace('<b>', '**')
            text = text.replace('</b>', '**')
            text = text.replace('<i>', '*')
            text = text.replace('</i>', '*')
            text = text.replace('<u>', '__')
            text = text.replace('</u>', '__')
            
            # 2. –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –±–∏—Ç—É—é —Ä–∞–∑–º–µ—Ç–∫—É
            import re
            
            # –£–±–∏—Ä–∞–µ–º –ø—É—Å—Ç—ã–µ —Ç–µ–≥–∏ —Ä–∞–∑–º–µ—Ç–∫–∏
            text = re.sub(r'\*\*\s*\*\*', '', text)  # **  **
            text = re.sub(r'\*\s*\*(?!\*)', '', text)  # * * (–Ω–æ –Ω–µ ***)
            text = re.sub(r'_{4,}', '__', text)  # ____ -> __
            text = re.sub(r'\|{4,}', '||', text)  # |||||| -> ||
            
            # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏
            text = re.sub(r'\*{3,}', '**', text)  # *** -> **
            text = re.sub(r'>{2,}\s*', '>', text)  # >> -> >
            
            # 3. –£–±–∏—Ä–∞–µ–º –≤–∏—Å—è—â–∏–µ —Å–∏–º–≤–æ–ª—ã —Ä–∞–∑–º–µ—Ç–∫–∏ –≤ –Ω–∞—á–∞–ª–µ —Å—Ç—Ä–æ–∫
            lines = text.split('\n')
            fixed_lines = []
            
            for line in lines:
                # –£–±–∏—Ä–∞–µ–º –≤–∏—Å—è—â–∏–µ —Å–∏–º–≤–æ–ª—ã —Ä–∞–∑–º–µ—Ç–∫–∏ —Å –Ω–∞—á–∞–ª–∞ —Å—Ç—Ä–æ–∫
                line = re.sub(r'^\s*\*\*\s*', '', line)  # ** –≤ –Ω–∞—á–∞–ª–µ —Å—Ç—Ä–æ–∫–∏
                line = re.sub(r'^\s*\*\s*(?!\*)', '', line)  # * –≤ –Ω–∞—á–∞–ª–µ —Å—Ç—Ä–æ–∫–∏ (–Ω–µ **)
                line = re.sub(r'^\s*__\s*', '', line)  # __ –≤ –Ω–∞—á–∞–ª–µ —Å—Ç—Ä–æ–∫–∏  
                line = re.sub(r'^\s*\|\|\s*', '', line)  # || –≤ –Ω–∞—á–∞–ª–µ —Å—Ç—Ä–æ–∫–∏
                fixed_lines.append(line)
            
            result_text = '\n'.join(fixed_lines)
            
            logger.debug("Telegram —Ä–∞–∑–º–µ—Ç–∫–∞ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∞: {} -> {} —Å–∏–º–≤–æ–ª–æ–≤", 
                        len(text), len(result_text))
            
            return result_text
            
        except Exception as e:
            logger.error("–û—à–∏–±–∫–∞ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è Telegram —Ä–∞–∑–º–µ—Ç–∫–∏: {}", str(e))
            # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
            return text
    
    def _parse_analysis_response(self, response_text: str) -> Dict[str, Any]:
        """–ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞ –æ—Ç OpenAI"""
        try:
            lines = response_text.strip().split('\n')
            
            result = {
                "relevance_score": None,
                "sentiment": None,
                "processed_text": "",
                "raw_response": response_text
            }
            
            processed_text_lines = []
            collecting_processed_text = False
            
            for line in lines:
                line = line.strip()
                
                # –ü–∞—Ä—Å–∏–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å
                if line.startswith("–†–ï–õ–ï–í–ê–ù–¢–ù–û–°–¢–¨:"):
                    try:
                        score_text = line.split(":")[1].strip()
                        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ü–∏—Ñ—Ä—É
                        score = int(''.join(filter(str.isdigit, score_text)))
                        if 1 <= score <= 10:
                            result["relevance_score"] = score
                    except:
                        logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –∏–∑: {}", line)
                
                # –ü–∞—Ä—Å–∏–º —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å
                elif line.startswith("–¢–û–ù–ê–õ–¨–ù–û–°–¢–¨:"):
                    sentiment_text = line.split(":")[1].strip().lower()
                    if "–ø–æ–∑–∏—Ç–∏–≤–Ω–∞—è" in sentiment_text or "–ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–∞—è" in sentiment_text:
                        result["sentiment"] = "–ø–æ–∑–∏—Ç–∏–≤–Ω–∞—è"
                    elif "–Ω–µ–≥–∞—Ç–∏–≤–Ω–∞—è" in sentiment_text or "–æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–∞—è" in sentiment_text:
                        result["sentiment"] = "–Ω–µ–≥–∞—Ç–∏–≤–Ω–∞—è"
                    elif "–Ω–µ–π—Ç—Ä–∞–ª—å–Ω–∞—è" in sentiment_text:
                        result["sentiment"] = "–Ω–µ–π—Ç—Ä–∞–ª—å–Ω–∞—è"
                
                # –ù–∞—á–∏–Ω–∞–µ–º —Å–æ–±–∏—Ä–∞—Ç—å —É–Ω–∏–∫–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ—Å—Ç
                elif line.startswith("–£–ù–ò–ö–ê–õ–ò–ó–ò–†–û–í–ê–ù–ù–´–ô –ü–û–°–¢:"):
                    collecting_processed_text = True
                elif collecting_processed_text and line:
                    processed_text_lines.append(line)
            
            # –°–æ–±–∏—Ä–∞–µ–º –ø–µ—Ä–µ–¥–µ–ª–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
            if processed_text_lines:
                raw_processed_text = "\n".join(processed_text_lines).strip()
                # –ü—Ä–∏–º–µ–Ω—è–µ–º –≤–∞–ª–∏–¥–∞—Ü–∏—é –∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ Telegram —Ä–∞–∑–º–µ—Ç–∫–∏
                result["processed_text"] = self._validate_and_fix_telegram_markup(raw_processed_text)
                
                # –õ–æ–≥–∏—Ä—É–µ–º –µ—Å–ª–∏ –±—ã–ª–∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è
                if result["processed_text"] != raw_processed_text:
                    logger.info("Telegram —Ä–∞–∑–º–µ—Ç–∫–∞ –±—ã–ª–∞ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∞ –≤–∞–ª–∏–¥–∞—Ç–æ—Ä–æ–º: {} -> {} —Å–∏–º–≤–æ–ª–æ–≤", 
                               len(raw_processed_text), len(result["processed_text"]))
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            if result["relevance_score"] is None:
                logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å, —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º 1")
                result["relevance_score"] = 1
            
            if not result["sentiment"]:
                logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å, —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º '–Ω–µ–π—Ç—Ä–∞–ª—å–Ω–∞—è'")
                result["sentiment"] = "–Ω–µ–π—Ç—Ä–∞–ª—å–Ω–∞—è"
            
            if not result["processed_text"]:
                logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –ø–µ—Ä–µ–¥–µ–ª–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª")
                result["processed_text"] = "–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ç–µ–∫—Å—Ç"
            
            return result
            
        except Exception as e:
            logger.error("–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–≤–µ—Ç–∞ OpenAI: {}", str(e))
            return {
                "relevance_score": 1,
                "sentiment": "–Ω–µ–π—Ç—Ä–∞–ª—å–Ω–∞—è", 
                "processed_text": "–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞",
                "raw_response": response_text,
                "error": str(e)
            }


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –∫–ª–∏–µ–Ω—Ç–∞
_openai_client: Optional[OpenAIClient] = None


def get_openai_client() -> OpenAIClient:
    """–ü–æ–ª—É—á–∏—Ç—å –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä OpenAI –∫–ª–∏–µ–Ω—Ç–∞"""
    global _openai_client
    
    if _openai_client is None:
        _openai_client = OpenAIClient()
    
    return _openai_client
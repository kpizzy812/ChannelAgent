"""
–ó–∞–¥–∞—á–∞ –æ—á–∏—Å—Ç–∫–∏ —Å—Ç–∞—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö
–ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ —É—Å—Ç–∞—Ä–µ–≤—à–∏—Ö –∑–∞–ø–∏—Å–µ–π –∏ —Ñ–∞–π–ª–æ–≤
"""

import os
import asyncio
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, Any, List, Optional

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ (–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û loguru)
from loguru import logger

# –õ–æ–∫–∞–ª—å–Ω—ã–µ –∏–º–ø–æ—Ä—Ç—ã
from src.database.connection import get_db_connection
from src.database.crud.post import get_post_crud
from src.database.crud.channel import get_channel_crud
from src.database.crud.user_post import get_user_post_crud
from src.database.models.post import PostStatus
from src.utils.config import get_config
from src.utils.exceptions import TaskExecutionError

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–≥–µ—Ä–∞ –º–æ–¥—É–ª—è
logger = logger.bind(module="scheduler_cleanup")


async def cleanup_old_posts() -> None:
    """–û—Å–Ω–æ–≤–Ω–∞—è –∑–∞–¥–∞—á–∞ –æ—á–∏—Å—Ç–∫–∏ —Å—Ç–∞—Ä—ã—Ö –ø–æ—Å—Ç–æ–≤ –∏ –¥–∞–Ω–Ω—ã—Ö"""
    try:
        logger.info("üßπ –ó–∞–ø—É—Å–∫ –∑–∞–¥–∞—á–∏ –æ—á–∏—Å—Ç–∫–∏ —Å—Ç–∞—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
        
        cleanup_stats = {
            "deleted_posts": 0,
            "archived_posts": 0,
            "deleted_files": 0,
            "cleaned_logs": False,
            "database_optimized": False
        }
        
        # 1. –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –ø–æ—Å—Ç–æ–≤
        deleted_posts = await cleanup_old_database_posts()
        cleanup_stats["deleted_posts"] = deleted_posts
        
        # 2. –ê—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç–∞—Ä—ã—Ö –ø–æ—Å—Ç–æ–≤
        archived_posts = await archive_old_posts()
        cleanup_stats["archived_posts"] = archived_posts
        
        # 3. –û—á–∏—Å—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤ –º–µ–¥–∏–∞
        deleted_files = await cleanup_media_files()
        cleanup_stats["deleted_files"] = deleted_files
        
        # 4. –û—á–∏—Å—Ç–∫–∞ –ª–æ–≥–æ–≤
        cleaned_logs = await cleanup_log_files()
        cleanup_stats["cleaned_logs"] = cleaned_logs
        
        # 5. –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ë–î
        optimized = await optimize_database()
        cleanup_stats["database_optimized"] = optimized
        
        # 6. –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        await cleanup_temp_files()
        
        logger.info("‚úÖ –û—á–∏—Å—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {} –ø–æ—Å—Ç–æ–≤ —É–¥–∞–ª–µ–Ω–æ, {} –∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω–æ, {} —Ñ–∞–π–ª–æ–≤ —É–¥–∞–ª–µ–Ω–æ",
                   cleanup_stats["deleted_posts"], 
                   cleanup_stats["archived_posts"],
                   cleanup_stats["deleted_files"])
        
    except Exception as e:
        logger.error("‚ùå –û—à–∏–±–∫–∞ –≤ –∑–∞–¥–∞—á–µ –æ—á–∏—Å—Ç–∫–∏: {}", str(e))
        raise TaskExecutionError("cleanup_task", str(e))


async def cleanup_old_database_posts() -> int:
    """
    –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –ø–æ—Å—Ç–æ–≤ –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
    
    Returns:
        –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–¥–∞–ª–µ–Ω–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤
    """
    try:
        logger.debug("üóëÔ∏è –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –ø–æ—Å—Ç–æ–≤ –∏–∑ –ë–î")
        
        # –£–¥–∞–ª—è–µ–º –ø–æ—Å—Ç—ã —Å—Ç–∞—Ä—à–µ 30 –¥–Ω–µ–π
        cutoff_date = datetime.now() - timedelta(days=30)
        
        post_crud = get_post_crud()
        
        # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ä—ã–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–Ω—ã–µ –ø–æ—Å—Ç—ã
        old_rejected_posts = await post_crud.get_posts_before_date_by_status(
            cutoff_date, PostStatus.REJECTED
        )
        
        deleted_count = 0
        
        # –£–¥–∞–ª—è–µ–º —Ç–æ–ª—å–∫–æ –æ—Ç–∫–ª–æ–Ω–µ–Ω–Ω—ã–µ –ø–æ—Å—Ç—ã (–æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã–µ –æ—Å—Ç–∞–≤–ª—è–µ–º –¥–ª—è –∏—Å—Ç–æ—Ä–∏–∏)
        for post in old_rejected_posts:
            try:
                success = await post_crud.delete_post_permanently(post.id)
                if success:
                    deleted_count += 1
                    logger.debug("–£–¥–∞–ª–µ–Ω —Å—Ç–∞—Ä—ã–π –æ—Ç–∫–ª–æ–Ω–µ–Ω–Ω—ã–π –ø–æ—Å—Ç {}", post.id)
                
            except Exception as e:
                logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å –ø–æ—Å—Ç {}: {}", post.id, str(e))
                continue
        
        # –¢–∞–∫–∂–µ –æ—á–∏—â–∞–µ–º –æ—á–µ–Ω—å —Å—Ç–∞—Ä—ã–µ pending –ø–æ—Å—Ç—ã (—Å—Ç–∞—Ä—à–µ 7 –¥–Ω–µ–π)
        old_pending_cutoff = datetime.now() - timedelta(days=7)
        old_pending_posts = await post_crud.get_posts_before_date_by_status(
            old_pending_cutoff, PostStatus.PENDING
        )
        
        for post in old_pending_posts:
            try:
                # –ü–µ—Ä–µ–≤–æ–¥–∏–º –≤ rejected –≤–º–µ—Å—Ç–æ –ø–æ–ª–Ω–æ–≥–æ —É–¥–∞–ª–µ–Ω–∏—è
                await post_crud.update_post_status(post.id, PostStatus.REJECTED)
                logger.debug("–°—Ç–∞—Ä—ã–π pending –ø–æ—Å—Ç {} –ø–æ–º–µ—á–µ–Ω –∫–∞–∫ rejected", post.id)
                
            except Exception as e:
                logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ç—É—Å –ø–æ—Å—Ç–∞ {}: {}", post.id, str(e))
        
        if deleted_count > 0:
            logger.info("–£–¥–∞–ª–µ–Ω–æ {} —Å—Ç–∞—Ä—ã—Ö –æ—Ç–∫–ª–æ–Ω–µ–Ω–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤", deleted_count)
        
        return deleted_count
        
    except Exception as e:
        logger.error("–û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ —Å—Ç–∞—Ä—ã—Ö –ø–æ—Å—Ç–æ–≤: {}", str(e))
        return 0


async def archive_old_posts() -> int:
    """
    –ê—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç–∞—Ä—ã—Ö –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤
    –ü–µ—Ä–µ–º–µ—â–µ–Ω–∏–µ –≤ –∞—Ä—Ö–∏–≤–Ω—É—é —Ç–∞–±–ª–∏—Ü—É –≤–º–µ—Å—Ç–æ —É–¥–∞–ª–µ–Ω–∏—è
    
    Returns:
        –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤
    """
    try:
        logger.debug("üì¶ –ê—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç–∞—Ä—ã—Ö –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤")
        
        # –ê—Ä—Ö–∏–≤–∏—Ä—É–µ–º –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã–µ –ø–æ—Å—Ç—ã —Å—Ç–∞—Ä—à–µ 90 –¥–Ω–µ–π
        archive_cutoff = datetime.now() - timedelta(days=90)
        
        post_crud = get_post_crud()
        old_published_posts = await post_crud.get_posts_before_date_by_status(
            archive_cutoff, PostStatus.POSTED
        )
        
        archived_count = 0
        
        for post in old_published_posts:
            try:
                # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –ø–µ—Ä–µ–Ω–æ—Å –≤ –∞—Ä—Ö–∏–≤–Ω—É—é —Ç–∞–±–ª–∏—Ü—É
                # –ü–æ–∫–∞ –ø—Ä–æ—Å—Ç–æ –ø–æ–º–µ—á–∞–µ–º —Ñ–ª–∞–≥–æ–º
                await post_crud.mark_post_as_archived(post.id)
                archived_count += 1
                logger.debug("–ê—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω –ø–æ—Å—Ç {}", post.id)
                
            except Exception as e:
                logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞—Ç—å –ø–æ—Å—Ç {}: {}", post.id, str(e))
                continue
        
        if archived_count > 0:
            logger.info("–ê—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω–æ {} —Å—Ç–∞—Ä—ã—Ö –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤", archived_count)
        
        return archived_count
        
    except Exception as e:
        logger.error("–û—à–∏–±–∫–∞ –∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω–∏—è –ø–æ—Å—Ç–æ–≤: {}", str(e))
        return 0


async def cleanup_media_files() -> int:
    """
    –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –º–µ–¥–∏–∞ —Ñ–∞–π–ª–æ–≤
    
    Returns:
        –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–¥–∞–ª–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
    """
    try:
        logger.debug("üñºÔ∏è –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –º–µ–¥–∏–∞ —Ñ–∞–π–ª–æ–≤")
        
        deleted_count = 0
        media_dirs = ["media", "photos", "temp", "downloads"]
        
        for dir_name in media_dirs:
            media_path = Path(dir_name)
            
            if not media_path.exists():
                continue
                
            cutoff_time = datetime.now() - timedelta(days=7)  # –§–∞–π–ª—ã —Å—Ç–∞—Ä—à–µ –Ω–µ–¥–µ–ª–∏
            
            try:
                for file_path in media_path.rglob("*"):
                    if file_path.is_file():
                        file_modified = datetime.fromtimestamp(file_path.stat().st_mtime)
                        
                        if file_modified < cutoff_time:
                            try:
                                file_path.unlink()
                                deleted_count += 1
                                logger.debug("–£–¥–∞–ª–µ–Ω —Å—Ç–∞—Ä—ã–π –º–µ–¥–∏–∞ —Ñ–∞–π–ª: {}", file_path.name)
                                
                            except Exception as e:
                                logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å —Ñ–∞–π–ª {}: {}", file_path, str(e))
                
            except Exception as e:
                logger.warning("–û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ {}: {}", dir_name, str(e))
        
        if deleted_count > 0:
            logger.info("–£–¥–∞–ª–µ–Ω–æ {} —Å—Ç–∞—Ä—ã—Ö –º–µ–¥–∏–∞ —Ñ–∞–π–ª–æ–≤", deleted_count)
        
        return deleted_count
        
    except Exception as e:
        logger.error("–û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –º–µ–¥–∏–∞ —Ñ–∞–π–ª–æ–≤: {}", str(e))
        return 0


async def cleanup_log_files() -> bool:
    """
    –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –ª–æ–≥ —Ñ–∞–π–ª–æ–≤
    
    Returns:
        True –µ—Å–ª–∏ –æ—á–∏—Å—Ç–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞
    """
    try:
        logger.debug("üìã –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –ª–æ–≥ —Ñ–∞–π–ª–æ–≤")
        
        logs_path = Path("logs")
        if not logs_path.exists():
            logger.debug("–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –ª–æ–≥–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            return True
        
        # –£–¥–∞–ª—è–µ–º –ª–æ–≥–∏ —Å—Ç–∞—Ä—à–µ 30 –¥–Ω–µ–π
        cutoff_time = datetime.now() - timedelta(days=30)
        deleted_count = 0
        
        for log_file in logs_path.glob("*.log*"):
            try:
                file_modified = datetime.fromtimestamp(log_file.stat().st_mtime)
                
                if file_modified < cutoff_time:
                    log_file.unlink()
                    deleted_count += 1
                    logger.debug("–£–¥–∞–ª–µ–Ω —Å—Ç–∞—Ä—ã–π –ª–æ–≥ —Ñ–∞–π–ª: {}", log_file.name)
                    
            except Exception as e:
                logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å –ª–æ–≥ —Ñ–∞–π–ª {}: {}", log_file, str(e))
        
        if deleted_count > 0:
            logger.info("–£–¥–∞–ª–µ–Ω–æ {} —Å—Ç–∞—Ä—ã—Ö –ª–æ–≥ —Ñ–∞–π–ª–æ–≤", deleted_count)
        
        return True
        
    except Exception as e:
        logger.error("–û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –ª–æ–≥ —Ñ–∞–π–ª–æ–≤: {}", str(e))
        return False


async def cleanup_temp_files() -> None:
    """–û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
    try:
        logger.debug("üóÇÔ∏è –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤")
        
        temp_dirs = ["tmp", "temp", ".temp", "cache"]
        deleted_count = 0
        
        for dir_name in temp_dirs:
            temp_path = Path(dir_name)
            
            if not temp_path.exists():
                continue
            
            try:
                for temp_file in temp_path.rglob("*"):
                    if temp_file.is_file():
                        temp_file.unlink()
                        deleted_count += 1
                        
            except Exception as e:
                logger.warning("–û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –≤—Ä–µ–º–µ–Ω–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ {}: {}", dir_name, str(e))
        
        if deleted_count > 0:
            logger.debug("–£–¥–∞–ª–µ–Ω–æ {} –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤", deleted_count)
            
    except Exception as e:
        logger.error("–û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤: {}", str(e))


async def optimize_database() -> bool:
    """
    –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
    
    Returns:
        True –µ—Å–ª–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∞
    """
    try:
        logger.debug("‚ö° –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö")
        
        async with get_db_connection() as conn:
            # VACUUM - –ø–µ—Ä–µ—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç –ë–î, —É–º–µ–Ω—å—à–∞–µ—Ç —Ä–∞–∑–º–µ—Ä
            await conn.execute("VACUUM")
            
            # ANALYZE - –æ–±–Ω–æ–≤–ª—è–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞ –∑–∞–ø—Ä–æ—Å–æ–≤
            await conn.execute("ANALYZE")
            
            await conn.commit()
        
        logger.info("‚úÖ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
        return True
        
    except Exception as e:
        logger.error("–û—à–∏–±–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö: {}", str(e))
        return False


async def cleanup_inactive_channels() -> int:
    """
    –û—á–∏—Å—Ç–∫–∞ –Ω–µ–∞–∫—Ç–∏–≤–Ω—ã—Ö –∫–∞–Ω–∞–ª–æ–≤
    –î–µ–∞–∫—Ç–∏–≤–∞—Ü–∏—è –∫–∞–Ω–∞–ª–æ–≤ –±–µ–∑ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –±–æ–ª–µ–µ –º–µ—Å—è—Ü–∞
    
    Returns:
        –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–µ–∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∫–∞–Ω–∞–ª–æ–≤
    """
    try:
        logger.debug("üì∫ –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ–∞–∫—Ç–∏–≤–Ω—ã—Ö –∫–∞–Ω–∞–ª–æ–≤")
        
        channel_crud = get_channel_crud()
        post_crud = get_post_crud()
        
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∞–∫—Ç–∏–≤–Ω—ã–µ –∫–∞–Ω–∞–ª—ã
        active_channels = await channel_crud.get_active_channels()
        
        inactive_cutoff = datetime.now() - timedelta(days=30)  # 30 –¥–Ω–µ–π –±–µ–∑ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
        deactivated_count = 0
        
        for channel in active_channels:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ –ø–æ—Å—Ç—ã –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π –º–µ—Å—è—Ü
            recent_posts = await post_crud.get_posts_by_channel_since(
                channel.channel_id, 
                inactive_cutoff
            )
            
            if not recent_posts:
                # –î–µ–∞–∫—Ç–∏–≤–∏—Ä—É–µ–º –∫–∞–Ω–∞–ª
                await channel_crud.deactivate_channel(channel.id)
                deactivated_count += 1
                
                channel_name = channel.title or channel.username or f"ID: {channel.channel_id}"
                logger.info("–î–µ–∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω –Ω–µ–∞–∫—Ç–∏–≤–Ω—ã–π –∫–∞–Ω–∞–ª: {}", channel_name)
        
        if deactivated_count > 0:
            logger.info("–î–µ–∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω–æ {} –Ω–µ–∞–∫—Ç–∏–≤–Ω—ã—Ö –∫–∞–Ω–∞–ª–æ–≤", deactivated_count)
        
        return deactivated_count
        
    except Exception as e:
        logger.error("–û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –Ω–µ–∞–∫—Ç–∏–≤–Ω—ã—Ö –∫–∞–Ω–∞–ª–æ–≤: {}", str(e))
        return 0


async def cleanup_user_posts() -> int:
    """
    –û—á–∏—Å—Ç–∫–∞ –Ω–µ–∞–∫—Ç–∏–≤–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ –ø–æ—Å—Ç–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    
    Returns:
        –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–¥–∞–ª–µ–Ω–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤
    """
    try:
        logger.debug("üìù –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ –ø–æ—Å—Ç–æ–≤")
        
        user_post_crud = get_user_post_crud()
        
        # –£–¥–∞–ª—è–µ–º –Ω–µ–∞–∫—Ç–∏–≤–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã —Å—Ç–∞—Ä—à–µ 90 –¥–Ω–µ–π
        cutoff_date = datetime.now() - timedelta(days=90)
        
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –Ω–µ–∞–∫—Ç–∏–≤–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã
        all_user_posts = await user_post_crud.get_active_user_posts()
        old_inactive_posts = [
            post for post in all_user_posts 
            if not post.is_active and post.created_at and post.created_at < cutoff_date
        ]
        
        deleted_count = 0
        
        for user_post in old_inactive_posts:
            try:
                success = await user_post_crud.delete_user_post(user_post.id)
                if success:
                    deleted_count += 1
                    logger.debug("–£–¥–∞–ª–µ–Ω —Å—Ç–∞—Ä—ã–π –ø—Ä–∏–º–µ—Ä –ø–æ—Å—Ç–∞ {}", user_post.id)
                    
            except Exception as e:
                logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å –ø—Ä–∏–º–µ—Ä –ø–æ—Å—Ç–∞ {}: {}", user_post.id, str(e))
        
        if deleted_count > 0:
            logger.info("–£–¥–∞–ª–µ–Ω–æ {} —Å—Ç–∞—Ä—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ –ø–æ—Å—Ç–æ–≤", deleted_count)
        
        return deleted_count
        
    except Exception as e:
        logger.error("–û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –ø—Ä–∏–º–µ—Ä–æ–≤ –ø–æ—Å—Ç–æ–≤: {}", str(e))
        return 0


async def get_cleanup_statistics() -> Dict[str, Any]:
    """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –¥–ª—è –æ—á–∏—Å—Ç–∫–∏"""
    try:
        post_crud = get_post_crud()
        channel_crud = get_channel_crud()
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ—Å—Ç–æ–≤
        total_posts = len(await post_crud.get_all_posts())
        rejected_posts = len(await post_crud.get_posts_by_status(PostStatus.REJECTED))
        old_posts = len(await post_crud.get_posts_before_date(
            datetime.now() - timedelta(days=30)
        ))
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫–∞–Ω–∞–ª–æ–≤
        total_channels = len(await channel_crud.get_all_channels())
        active_channels = len(await channel_crud.get_active_channels())
        
        # –†–∞–∑–º–µ—Ä –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
        db_path = Path(get_config().DATABASE_PATH or "./data/channel_agent.db")
        db_size = db_path.stat().st_size if db_path.exists() else 0
        
        return {
            "total_posts": total_posts,
            "rejected_posts": rejected_posts,
            "old_posts": old_posts,
            "total_channels": total_channels,
            "active_channels": active_channels,
            "database_size_bytes": db_size,
            "database_size_mb": round(db_size / (1024 * 1024), 2)
        }
        
    except Exception as e:
        logger.error("–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –æ—á–∏—Å—Ç–∫–∏: {}", str(e))
        return {}
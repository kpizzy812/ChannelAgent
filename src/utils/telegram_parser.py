"""
–ü–∞—Ä—Å–µ—Ä —Å—Å—ã–ª–æ–∫ Telegram –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø–æ—Å—Ç–æ–≤
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–æ—Å—Ç–æ–≤ –ø–æ —Å—Å—ã–ª–∫–∞–º –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤ –ø—Ä–∏–º–µ—Ä—ã —Å—Ç–∏–ª—è
"""

import re
from typing import Optional, Dict, Any
from urllib.parse import urlparse, parse_qs

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ (–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û loguru)
from loguru import logger

# –õ–æ–∫–∞–ª—å–Ω—ã–µ –∏–º–ø–æ—Ä—Ç—ã
from src.utils.exceptions import TelegramParsingError

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–≥–µ—Ä–∞ –º–æ–¥—É–ª—è
logger = logger.bind(module="telegram_parser")


def _utf16_offset_to_python(text: str, utf16_offset: int) -> int:
    """
    –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç UTF-16 offset (–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–π Telegram API) –≤ Python string offset.

    Telegram API –∏—Å–ø–æ–ª—å–∑—É–µ—Ç UTF-16 code units –¥–ª—è offset'–æ–≤ –≤ entities.
    –°–∏–º–≤–æ–ª—ã –≤–Ω–µ BMP (–Ω–∞–ø—Ä–∏–º–µ—Ä —ç–º–æ–¥–∑–∏ üü†) –∑–∞–Ω–∏–º–∞—é—Ç 2 UTF-16 code units,
    –Ω–æ —Ç–æ–ª—å–∫–æ 1 —Å–∏–º–≤–æ–ª –≤ Python —Å—Ç—Ä–æ–∫–µ.

    Args:
        text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
        utf16_offset: Offset –≤ UTF-16 code units

    Returns:
        Offset –≤ Python —Å–∏–º–≤–æ–ª–∞—Ö
    """
    # –ö–æ–¥–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç –≤ UTF-16 LE (–±–µ–∑ BOM)
    utf16_bytes = text.encode('utf-16-le')

    # –ù–∞—Ö–æ–¥–∏–º –ø–æ–∑–∏—Ü–∏—é –≤ –±–∞–π—Ç–∞—Ö (2 –±–∞–π—Ç–∞ –Ω–∞ UTF-16 code unit)
    byte_offset = utf16_offset * 2

    # –î–µ–∫–æ–¥–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç –¥–æ —ç—Ç–æ–π –ø–æ–∑–∏—Ü–∏–∏ —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å Python offset
    if byte_offset > len(utf16_bytes):
        byte_offset = len(utf16_bytes)

    prefix_text = utf16_bytes[:byte_offset].decode('utf-16-le', errors='replace')
    return len(prefix_text)


class TelegramLinkParser:
    """–ü–∞—Ä—Å–µ—Ä —Å—Å—ã–ª–æ–∫ Telegram"""
    
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞—Ä—Å–µ—Ä–∞"""
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã —Å—Å—ã–ª–æ–∫ Telegram
        self.link_patterns = {
            # https://t.me/channel_name/123
            "public_channel": re.compile(r'https?://t\.me/([^/]+)/(\d+)'),
            # https://t.me/c/1234567890/123 (–ø—Ä–∏–≤–∞—Ç–Ω—ã–µ –∫–∞–Ω–∞–ª—ã)
            "private_channel": re.compile(r'https?://t\.me/c/(\d+)/(\d+)'),
            # tg://resolve?domain=channel_name&post=123
            "tg_protocol": re.compile(r'tg://resolve\?domain=([^&]+)&post=(\d+)'),
            # https://telegram.me/channel_name/123 (—Å—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç)
            "telegram_me": re.compile(r'https?://telegram\.me/([^/]+)/(\d+)')
        }
        
        logger.debug("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –ø–∞—Ä—Å–µ—Ä —Å—Å—ã–ª–æ–∫ Telegram")
    
    def parse_telegram_link(self, link: str) -> Optional[Dict[str, Any]]:
        """
        –ü–∞—Ä—Å–∏—Ç —Å—Å—ã–ª–∫—É Telegram –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        
        Args:
            link: –°—Å—ã–ª–∫–∞ –Ω–∞ –ø–æ—Å—Ç –≤ Telegram
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –ø–æ—Å—Ç–µ –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
        """
        try:
            link = link.strip()
            logger.debug("–ü–∞—Ä—Å–∏–Ω–≥ —Å—Å—ã–ª–∫–∏: {}", link)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω
            for link_type, pattern in self.link_patterns.items():
                match = pattern.match(link)
                if match:
                    return self._extract_link_info(link_type, match, link)
            
            logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ñ–æ—Ä–º–∞—Ç —Å—Å—ã–ª–∫–∏: {}", link)
            return None
            
        except Exception as e:
            logger.error("–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å—Å—ã–ª–∫–∏ {}: {}", link, str(e))
            return None
    
    def _extract_link_info(self, link_type: str, match, original_link: str) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ—á—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω–æ–π —Å—Å—ã–ª–∫–∏"""
        
        if link_type == "public_channel":
            channel_username = match.group(1)
            message_id = int(match.group(2))
            
            return {
                "type": "public_channel",
                "channel_username": channel_username,
                "message_id": message_id,
                "channel_id": None,
                "original_link": original_link,
                "is_private": False
            }
        
        elif link_type == "private_channel":
            channel_id = int(match.group(1))
            message_id = int(match.group(2))
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º ID –≤ –ø–æ–ª–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
            full_channel_id = int(f"-100{channel_id}")
            
            return {
                "type": "private_channel", 
                "channel_username": None,
                "message_id": message_id,
                "channel_id": full_channel_id,
                "original_link": original_link,
                "is_private": True
            }
        
        elif link_type == "tg_protocol":
            channel_username = match.group(1)
            message_id = int(match.group(2))
            
            return {
                "type": "tg_protocol",
                "channel_username": channel_username,
                "message_id": message_id,
                "channel_id": None,
                "original_link": original_link,
                "is_private": False
            }
        
        elif link_type == "telegram_me":
            channel_username = match.group(1)
            message_id = int(match.group(2))
            
            return {
                "type": "telegram_me",
                "channel_username": channel_username,
                "message_id": message_id,
                "channel_id": None,
                "original_link": original_link,
                "is_private": False
            }
        
        return None
    
    def validate_telegram_link(self, link: str) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å—Å—ã–ª–∫–∞ –≤–∞–ª–∏–¥–Ω–æ–π —Å—Å—ã–ª–∫–æ–π Telegram
        
        Args:
            link: –°—Å—ã–ª–∫–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
            
        Returns:
            True –µ—Å–ª–∏ —Å—Å—ã–ª–∫–∞ –≤–∞–ª–∏–¥–Ω–∞
        """
        return self.parse_telegram_link(link) is not None
    
    def extract_channel_info(self, link: str) -> Optional[Dict[str, Any]]:
        """
        –ò–∑–≤–ª–µ—á—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–∞–Ω–∞–ª–µ –∏–∑ —Å—Å—ã–ª–∫–∏
        
        Args:
            link: –°—Å—ã–ª–∫–∞ –Ω–∞ –ø–æ—Å—Ç
            
        Returns:
            –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–∞–Ω–∞–ª–µ
        """
        link_info = self.parse_telegram_link(link)
        if not link_info:
            return None
        
        return {
            "username": link_info.get("channel_username"),
            "channel_id": link_info.get("channel_id"),
            "is_private": link_info.get("is_private", False)
        }
    
    def normalize_telegram_link(self, link: str) -> Optional[str]:
        """
        –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å —Å—Å—ã–ª–∫—É Telegram –∫ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–º—É —Ñ–æ—Ä–º–∞—Ç—É
        
        Args:
            link: –ò—Å—Ö–æ–¥–Ω–∞—è —Å—Å—ã–ª–∫–∞
            
        Returns:
            –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è —Å—Å—ã–ª–∫–∞ –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
        """
        link_info = self.parse_telegram_link(link)
        if not link_info:
            return None
        
        if link_info["is_private"]:
            # –î–ª—è –ø—Ä–∏–≤–∞—Ç–Ω—ã—Ö –∫–∞–Ω–∞–ª–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º c/ —Ñ–æ—Ä–º–∞—Ç
            channel_id = str(link_info["channel_id"])[4:]  # –£–±–∏—Ä–∞–µ–º -100
            return f"https://t.me/c/{channel_id}/{link_info['message_id']}"
        else:
            # –î–ª—è –ø—É–±–ª–∏—á–Ω—ã—Ö –∫–∞–Ω–∞–ª–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º username —Ñ–æ—Ä–º–∞—Ç
            return f"https://t.me/{link_info['channel_username']}/{link_info['message_id']}"
    
    def is_supported_link(self, link: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –ª–∏ —Ñ–æ—Ä–º–∞—Ç —Å—Å—ã–ª–∫–∏"""
        return any(pattern.match(link.strip()) for pattern in self.link_patterns.values())


class TelegramPostExtractor:
    """–ò–∑–≤–ª–µ–∫–∞—Ç–µ–ª—å –ø–æ—Å—Ç–æ–≤ Telegram —á–µ—Ä–µ–∑ UserBot"""
    
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏–∑–≤–ª–µ–∫–∞—Ç–µ–ª—è"""
        self.parser = TelegramLinkParser()
        logger.debug("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –∏–∑–≤–ª–µ–∫–∞—Ç–µ–ª—å –ø–æ—Å—Ç–æ–≤ Telegram")
    
    def _extract_formatted_text(self, message) -> str:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –≤ HTML —Ñ–æ—Ä–º–∞—Ç–µ –¥–ª—è Telegram
        
        Args:
            message: –û–±—ä–µ–∫—Ç —Å–æ–æ–±—â–µ–Ω–∏—è Telethon
            
        Returns:
            –¢–µ–∫—Å—Ç –≤ HTML —Ñ–æ—Ä–º–∞—Ç–µ –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ Telegram –±–æ—Ç–µ
        """
        try:
            # –ü–æ–ª—É—á–∞–µ–º —á–∏—Å—Ç—ã–π —Ç–µ–∫—Å—Ç
            raw_text = message.message or message.text or ""
            if not raw_text:
                return ""
            
            # –î–ï–¢–ê–õ–¨–ù–û–ï –õ–û–ì–ò–†–û–í–ê–ù–ò–ï –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ —Ä–∞–∑–ª–∏—á–∏–π
            message_type = type(message).__name__
            has_entities = hasattr(message, 'entities') and message.entities
            entities_count = len(message.entities) if has_entities else 0
            
            logger.debug("–ü–∞—Ä—Å–∏–Ω–≥ —Å–æ–æ–±—â–µ–Ω–∏—è: —Ç–∏–ø={}, —Ç–µ–∫—Å—Ç={} —Å–∏–º–≤–æ–ª–æ–≤, entities={}", 
                        message_type, len(raw_text), entities_count)
            
            if has_entities and entities_count > 0:
                # –õ–æ–≥–∏—Ä—É–µ–º —Ç–∏–ø—ã entities –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
                entity_types = [type(entity).__name__ for entity in message.entities[:3]]  # –ü–µ—Ä–≤—ã–µ 3
                logger.debug("–¢–∏–ø—ã entities: {}", entity_types)
            
            # –ï—Å–ª–∏ –Ω–µ—Ç entities, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —á–∏—Å—Ç—ã–π —Ç–µ–∫—Å—Ç
            if not has_entities:
                logger.debug("–ù–µ—Ç entities, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —á–∏—Å—Ç—ã–π —Ç–µ–∫—Å—Ç")
                return raw_text
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç–æ–π –ø–æ–¥—Ö–æ–¥ - –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ HTML –¥–ª—è Telegram
            return self._convert_to_telegram_html(raw_text, message.entities)
                
        except Exception as e:
            logger.error("–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞: {}", str(e))
            # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —á–∏—Å—Ç—ã–π —Ç–µ–∫—Å—Ç –±–µ–∑ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            return message.message or message.text or ""
    
    def _convert_to_telegram_html(self, text: str, entities) -> str:
        """
        –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç entities –≤ HTML —Ñ–æ—Ä–º–∞—Ç –∏—Å–ø–æ–ª—å–∑—É—è –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π –ø–∞—Ä—Å–µ—Ä Telethon
        
        Args:
            text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è
            entities: –°–ø–∏—Å–æ–∫ entities –∏–∑ Telethon
            
        Returns:
            –¢–µ–∫—Å—Ç –≤ HTML —Ñ–æ—Ä–º–∞—Ç–µ –¥–ª—è Telegram
        """
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π HTML –ø–∞—Ä—Å–µ—Ä Telethon –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            from telethon.extensions import html
            
            logger.debug("–ù–∞—á–∏–Ω–∞–µ—Ç—Å—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —á–µ—Ä–µ–∑ html.unparse: —Ç–µ–∫—Å—Ç={} —Å–∏–º–≤–æ–ª–æ–≤, entities={}", 
                        len(text), len(entities) if entities else 0)
            
            # –í—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π –ø–∞—Ä—Å–µ—Ä –ø—Ä–∞–≤–∏–ª—å–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤—Å–µ entities
            formatted_text = html.unparse(text, entities or [])
            
            logger.debug("–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ: {} —Å–∏–º–≤–æ–ª–æ–≤", len(formatted_text))
            return formatted_text
            
        except Exception as e:
            logger.error("–û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –≤ HTML —á–µ—Ä–µ–∑ –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π –ø–∞—Ä—Å–µ—Ä: {} | –¢–µ–∫—Å—Ç: '{}' | Entities: {}", 
                        str(e), text[:100] + "..." if len(text) > 100 else text, 
                        len(entities) if entities else 0)
            # Fallback –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É —Ç–µ–∫—Å—Ç—É –ø—Ä–∏ –æ—à–∏–±–∫–µ
            return text
    
    
    
    
    async def extract_post_from_link(self, link: str, userbot_client) -> Optional[Dict[str, Any]]:
        """
        –ò–∑–≤–ª–µ—á—å –ø–æ—Å—Ç –ø–æ —Å—Å—ã–ª–∫–µ —á–µ—Ä–µ–∑ UserBot
        
        Args:
            link: –°—Å—ã–ª–∫–∞ –Ω–∞ –ø–æ—Å—Ç
            userbot_client: –ö–ª–∏–µ–Ω—Ç UserBot (Telethon)
            
        Returns:
            –î–∞–Ω–Ω—ã–µ –ø–æ—Å—Ç–∞ –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
        """
        try:
            # –ü–∞—Ä—Å–∏–º —Å—Å—ã–ª–∫—É
            link_info = self.parser.parse_telegram_link(link)
            if not link_info:
                logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å —Å—Å—ã–ª–∫—É: {}", link)
                return None
            
            logger.info("–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–æ—Å—Ç–∞: –∫–∞–Ω–∞–ª={}, —Å–æ–æ–±—â–µ–Ω–∏–µ={}", 
                       link_info.get("channel_username") or link_info.get("channel_id"),
                       link_info["message_id"])
            
            # –ü–æ–ª—É—á–∞–µ–º —Å—É—â–Ω–æ—Å—Ç—å –∫–∞–Ω–∞–ª–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ –º–µ—Ç–æ–¥–∞
            entity = None
            if link_info["channel_username"]:
                entity = await userbot_client.safe_api_call(
                    userbot_client.client.get_entity,
                    link_info["channel_username"]
                )
            elif link_info["channel_id"]:
                entity = await userbot_client.safe_api_call(
                    userbot_client.client.get_entity,
                    link_info["channel_id"]
                )
            else:
                logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∫–∞–Ω–∞–ª –∏–∑ —Å—Å—ã–ª–∫–∏: {}", link)
                return None
            
            if not entity:
                logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å—É—â–Ω–æ—Å—Ç—å –∫–∞–Ω–∞–ª–∞ –¥–ª—è —Å—Å—ã–ª–∫–∏: {}", link)
                return None
            
            # –ü–æ–ª—É—á–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ –º–µ—Ç–æ–¥–∞
            message = await userbot_client.safe_api_call(
                userbot_client.client.get_messages,
                entity,
                ids=link_info["message_id"]
            )
            
            if not message:
                logger.error("–°–æ–æ–±—â–µ–Ω–∏–µ {} –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ –∫–∞–Ω–∞–ª–µ", link_info["message_id"])
                return None
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            formatted_text = self._extract_formatted_text(message)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ—Å—Ç–∞
            post_data = {
                "text": formatted_text,
                "raw_text": message.message or message.text or "",  # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—ã—Ä–æ–π —Ç–µ–∫—Å—Ç
                "message_id": message.id,
                "channel_id": int(f"-100{entity.id}") if hasattr(entity, 'id') else None,
                "channel_title": getattr(entity, 'title', None),
                "channel_username": getattr(entity, 'username', None),
                "date": message.date,
                "has_media": bool(message.media),
                "media_type": type(message.media).__name__ if message.media else None,
                "source_link": self.parser.normalize_telegram_link(link),
                "views": getattr(message, 'views', None),
                "forwards": getattr(message, 'forwards', None),
                "entities": getattr(message, 'entities', None)  # –°–æ—Ö—Ä–∞–Ω—è–µ–º entities –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            }
            
            logger.info("–ü–æ—Å—Ç —É—Å–ø–µ—à–Ω–æ –∏–∑–≤–ª–µ—á–µ–Ω: {} —Å–∏–º–≤–æ–ª–æ–≤, –º–µ–¥–∏–∞: {}", 
                       len(post_data["text"]), post_data["has_media"])
            
            return post_data
            
        except Exception as e:
            logger.error("–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø–æ—Å—Ç–∞ –∏–∑ —Å—Å—ã–ª–∫–∏ {}: {}", link, str(e))
            return None  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º None –≤–º–µ—Å—Ç–æ exception –¥–ª—è –±–æ–ª–µ–µ graceful handling
    
    async def extract_multiple_posts(
        self, 
        links: list[str], 
        userbot_client
    ) -> Dict[str, Any]:
        """
        –ò–∑–≤–ª–µ—á—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø–æ—Å—Ç–æ–≤ –ø–æ —Å—Å—ã–ª–∫–∞–º
        
        Args:
            links: –°–ø–∏—Å–æ–∫ —Å—Å—ã–ª–æ–∫
            userbot_client: –ö–ª–∏–µ–Ω—Ç UserBot
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–∑–≤–ª–µ—á–µ–Ω–∏—è
        """
        results = {
            "successful": [],
            "failed": [],
            "total": len(links)
        }
        
        for i, link in enumerate(links, 1):
            try:
                logger.info("–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Å—ã–ª–∫–∏ {}/{}: {}", i, len(links), link[:50])
                
                post_data = await self.extract_post_from_link(link, userbot_client)
                if post_data:
                    results["successful"].append({
                        "link": link,
                        "post": post_data
                    })
                    logger.debug("–ü–æ—Å—Ç {} —É—Å–ø–µ—à–Ω–æ –∏–∑–≤–ª–µ—á–µ–Ω", i)
                else:
                    results["failed"].append({
                        "link": link,
                        "error": "–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –ø–æ—Å—Ç"
                    })
                    logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –ø–æ—Å—Ç {}", i)
                    
            except Exception as e:
                logger.error("–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—Å—ã–ª–∫–∏ {}: {}", i, str(e))
                results["failed"].append({
                    "link": link,
                    "error": str(e)
                })
        
        logger.info("–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ: —É—Å–ø–µ—à–Ω–æ={}, –æ—à–∏–±–æ–∫={}", 
                   len(results["successful"]), len(results["failed"]))
        
        return results


# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ —ç–∫–∑–µ–º–ø–ª—è—Ä—ã
_telegram_parser: Optional[TelegramLinkParser] = None
_post_extractor: Optional[TelegramPostExtractor] = None


def get_telegram_parser() -> TelegramLinkParser:
    """–ü–æ–ª—É—á–∏—Ç—å –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –ø–∞—Ä—Å–µ—Ä–∞"""
    global _telegram_parser
    
    if _telegram_parser is None:
        _telegram_parser = TelegramLinkParser()
    
    return _telegram_parser


def get_post_extractor() -> TelegramPostExtractor:
    """–ü–æ–ª—É—á–∏—Ç—å –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –∏–∑–≤–ª–µ–∫–∞—Ç–µ–ª—è –ø–æ—Å—Ç–æ–≤"""
    global _post_extractor
    
    if _post_extractor is None:
        _post_extractor = TelegramPostExtractor()
    
    return _post_extractor


def format_entities_to_html(text: str, entities: list) -> str:
    """
    –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç MessageEntity –≤ HTML —Ñ–æ—Ä–º–∞—Ç –¥–ª—è Telegram

    –í–ê–ñ–ù–û: –ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç UTF-16 offset'—ã –∫–æ—Ç–æ—Ä—ã–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç Telegram API.

    Args:
        text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
        entities: –°–ø–∏—Å–æ–∫ MessageEntity –∏–∑ aiogram

    Returns:
        –¢–µ–∫—Å—Ç –≤ HTML —Ñ–æ—Ä–º–∞—Ç–µ
    """
    try:
        if not entities:
            return text

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º entities –ø–æ offset –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
        sorted_entities = sorted(entities, key=lambda e: e.offset)

        # –°–ø–∏—Å–æ–∫ –¥–ª—è –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        result = []
        last_python_offset = 0

        for entity in sorted_entities:
            # –ö–†–ò–¢–ò–ß–ù–û: –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º UTF-16 offset –≤ Python offset
            start = _utf16_offset_to_python(text, entity.offset)
            end = _utf16_offset_to_python(text, entity.offset + entity.length)

            # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç –¥–æ entity
            if start > last_python_offset:
                result.append(text[last_python_offset:start])

            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç entity —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ Python offset'–∞–º–∏
            entity_text = text[start:end]

            # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º HTML —Å–∏–º–≤–æ–ª—ã –≤ —Ç–µ–∫—Å—Ç–µ
            from html import escape
            escaped_text = escape(entity_text)

            # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ —Ç–µ–≥–∏
            if entity.type == "bold":
                result.append(f"<b>{escaped_text}</b>")
            elif entity.type == "italic":
                result.append(f"<i>{escaped_text}</i>")
            elif entity.type == "underline":
                result.append(f"<u>{escaped_text}</u>")
            elif entity.type == "strikethrough":
                result.append(f"<s>{escaped_text}</s>")
            elif entity.type == "spoiler":
                result.append(f"<span class=\"tg-spoiler\">{escaped_text}</span>")
            elif entity.type == "code":
                result.append(f"<code>{escaped_text}</code>")
            elif entity.type == "pre":
                result.append(f"<pre>{escaped_text}</pre>")
            elif entity.type == "text_link":
                url = getattr(entity, 'url', '')
                result.append(f"<a href=\"{escape(url)}\">{escaped_text}</a>")
            elif entity.type == "blockquote":
                result.append(f"<blockquote>{escaped_text}</blockquote>")
            else:
                # –î–ª—è –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã—Ö —Ç–∏–ø–æ–≤ –ø—Ä–æ—Å—Ç–æ –¥–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç
                logger.debug("–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø entity: {}, –¥–æ–±–∞–≤–ª—è–µ–º –∫–∞–∫ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç", entity.type)
                result.append(escaped_text)

            last_python_offset = end

        # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å—Ç–∞–≤—à–∏–π—Å—è —Ç–µ–∫—Å—Ç
        if last_python_offset < len(text):
            result.append(text[last_python_offset:])

        return ''.join(result)

    except Exception as e:
        logger.error("–û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ entities –≤ HTML: {}", str(e))
        from html import escape
        return escape(text)  # Fallback –∫ —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–º—É —Ç–µ–∫—Å—Ç—É


def extract_formatted_text(text: str, entities: list) -> str:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –∏–∑ Telegram message
    
    Args:
        text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è
        entities: –°–ø–∏—Å–æ–∫ MessageEntity
        
    Returns:
        –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π HTML —Ç–µ–∫—Å—Ç
    """
    try:
        logger.debug("–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞: {} —Å–∏–º–≤–æ–ª–æ–≤, {} entities", 
                    len(text), len(entities) if entities else 0)
        
        if not entities:
            from html import escape
            return escape(text)
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º format_entities_to_html –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏
        html_text = format_entities_to_html(text, entities)
        
        logger.debug("–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –≥–æ—Ç–æ–≤: {} —Å–∏–º–≤–æ–ª–æ–≤", len(html_text))
        return html_text
        
    except Exception as e:
        logger.error("–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞: {}", str(e))
        from html import escape
        return escape(text)


def entities_to_telethon_markdown(text: str, entities: list) -> str:
    """
    –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç aiogram MessageEntity –≤ Telethon Markdown —Ñ–æ—Ä–º–∞—Ç

    –í–ê–ñ–ù–û: –ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç UTF-16 offset'—ã –∫–æ—Ç–æ—Ä—ã–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç Telegram API.
    –≠–º–æ–¥–∑–∏ –∏ –¥—Ä—É–≥–∏–µ —Å–∏–º–≤–æ–ª—ã –≤–Ω–µ BMP –∑–∞–Ω–∏–º–∞—é—Ç 2 UTF-16 code units, –Ω–æ 1 Python —Å–∏–º–≤–æ–ª.

    Telethon Markdown —Å–∏–Ω—Ç–∞–∫—Å–∏—Å:
    - Bold: **—Ç–µ–∫—Å—Ç**
    - Italic: __—Ç–µ–∫—Å—Ç__ (–¥–≤–æ–π–Ω–æ–µ –ø–æ–¥—á—ë—Ä–∫–∏–≤–∞–Ω–∏–µ)
    - Code: `—Ç–µ–∫—Å—Ç`
    - Strike: ~~—Ç–µ–∫—Å—Ç~~
    - Spoiler: [—Ç–µ–∫—Å—Ç](spoiler)
    - Link: [—Ç–µ–∫—Å—Ç](url)

    Args:
        text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è
        entities: –°–ø–∏—Å–æ–∫ MessageEntity –∏–∑ aiogram

    Returns:
        –¢–µ–∫—Å—Ç —Å Telethon Markdown —Ä–∞–∑–º–µ—Ç–∫–æ–π
    """
    try:
        if not entities:
            return text

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º entities –ø–æ offset –≤ –æ–±—Ä–∞—Ç–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ
        # —á—Ç–æ–±—ã –≤—Å—Ç–∞–≤–ª—è—Ç—å —Ä–∞–∑–º–µ—Ç–∫—É —Å –∫–æ–Ω—Ü–∞ –∏ –Ω–µ —Å–±–∏–≤–∞—Ç—å offsets
        sorted_entities = sorted(entities, key=lambda e: e.offset, reverse=True)

        result = text

        for entity in sorted_entities:
            # –ö–†–ò–¢–ò–ß–ù–û: –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º UTF-16 offset –≤ Python offset
            utf16_start = entity.offset
            utf16_end = entity.offset + entity.length

            start = _utf16_offset_to_python(text, utf16_start)
            end = _utf16_offset_to_python(text, utf16_end)

            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç entity –∏–∑ –û–†–ò–ì–ò–ù–ê–õ–¨–ù–û–ì–û —Ç–µ–∫—Å—Ç–∞ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ offset'–∞–º–∏
            entity_text = text[start:end]

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø entity –∏ –ø—Ä–∏–º–µ–Ω—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â—É—é —Ä–∞–∑–º–µ—Ç–∫—É
            entity_type = getattr(entity, 'type', None)

            if entity_type == "bold":
                replacement = f"**{entity_text}**"
            elif entity_type == "italic":
                replacement = f"__{entity_text}__"
            elif entity_type == "code":
                replacement = f"`{entity_text}`"
            elif entity_type == "pre":
                # –î–ª—è pre –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç—Ä–æ–π–Ω—ã–µ backticks
                replacement = f"```\n{entity_text}\n```"
            elif entity_type == "strikethrough":
                replacement = f"~~{entity_text}~~"
            elif entity_type == "underline":
                # Telethon –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç underline –≤ Markdown, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–∞–∫ –µ—Å—Ç—å
                replacement = entity_text
            elif entity_type == "spoiler":
                replacement = f"[{entity_text}](spoiler)"
            elif entity_type == "text_link":
                url = getattr(entity, 'url', '')
                replacement = f"[{entity_text}]({url})"
            elif entity_type == "blockquote":
                # –î–æ–±–∞–≤–ª—è–µ–º > –ø–µ—Ä–µ–¥ –∫–∞–∂–¥–æ–π —Å—Ç—Ä–æ–∫–æ–π
                lines = entity_text.split('\n')
                quoted_lines = ['>' + line for line in lines]
                replacement = '\n'.join(quoted_lines)
            else:
                # –î–ª—è –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã—Ö —Ç–∏–ø–æ–≤ –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å
                logger.debug("–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø entity –¥–ª—è Markdown: {}", entity_type)
                replacement = entity_text

            # –ó–∞–º–µ–Ω—è–µ–º —Ç–µ–∫—Å—Ç —Å —Ä–∞–∑–º–µ—Ç–∫–æ–π - –∏—Å–ø–æ–ª—å–∑—É–µ–º Python offset'—ã –¥–ª—è result
            # –¢–∞–∫ –∫–∞–∫ –º—ã –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å –∫–æ–Ω—Ü–∞, result –µ—â—ë –Ω–µ –∏–∑–º–µ–Ω—ë–Ω –≤ —ç—Ç–æ–π –ø–æ–∑–∏—Ü–∏–∏
            result = result[:start] + replacement + result[end:]

        logger.debug("–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ Telethon Markdown: {} -> {} —Å–∏–º–≤–æ–ª–æ–≤",
                    len(text), len(result))
        return result

    except Exception as e:
        logger.error("–û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ entities –≤ Telethon Markdown: {}", str(e))
        return text  # Fallback –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É —Ç–µ–∫—Å—Ç—É


def extract_aiogram_formatting(message) -> str:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–∑ aiogram Message –≤ Telethon Markdown —Ñ–æ—Ä–º–∞—Ç

    –≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –Ω—É–∂–Ω–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —à–∞–±–ª–æ–Ω–æ–≤ daily posts.

    Args:
        message: aiogram Message –æ–±—ä–µ–∫—Ç

    Returns:
        –¢–µ–∫—Å—Ç —Å Telethon Markdown —Ä–∞–∑–º–µ—Ç–∫–æ–π
    """
    try:
        # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç –∏ entities
        if message.text:
            raw_text = message.text
            entities = message.entities
        elif message.caption:
            raw_text = message.caption
            entities = message.caption_entities
        else:
            return ""

        if not raw_text:
            return ""

        # –ï—Å–ª–∏ –Ω–µ—Ç entities, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å
        if not entities:
            logger.debug("–ù–µ—Ç entities, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Å—ã—Ä–æ–π —Ç–µ–∫—Å—Ç: {} —Å–∏–º–≤–æ–ª–æ–≤", len(raw_text))
            return raw_text

        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º entities –≤ Telethon Markdown
        formatted = entities_to_telethon_markdown(raw_text, entities)

        logger.info("–ò–∑–≤–ª–µ—á–µ–Ω–æ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ: {} entities, {} -> {} —Å–∏–º–≤–æ–ª–æ–≤",
                   len(entities), len(raw_text), len(formatted))

        return formatted

    except Exception as e:
        logger.error("–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è aiogram: {}", str(e))
        # Fallback
        return message.text or message.caption or ""


def validate_telegram_html(html_text: str) -> str:
    """
    –í–∞–ª–∏–¥–∏—Ä—É–µ—Ç –∏ –∏—Å–ø—Ä–∞–≤–ª—è–µ—Ç HTML –¥–ª—è Telegram
    –£–±–∏—Ä–∞–µ—Ç –≤–ª–æ–∂–µ–Ω–Ω—ã–µ —Ç–µ–≥–∏ –∏ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏
    
    Args:
        html_text: HTML —Ç–µ–∫—Å—Ç –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
        
    Returns:
        –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π HTML —Ç–µ–∫—Å—Ç
    """
    try:
        import re
        from html import escape
        
        # –õ–æ–≥–∏—Ä—É–µ–º –≤—Ö–æ–¥—è—â–∏–π HTML –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        logger.debug("–í–∞–ª–∏–¥–∞—Ü–∏—è HTML: {} —Å–∏–º–≤–æ–ª–æ–≤", len(html_text))
        
        # –£–±–∏—Ä–∞–µ–º –≤–ª–æ–∂–µ–Ω–Ω—ã–µ —Ç–µ–≥–∏ –æ–¥–Ω–æ–≥–æ —Ç–∏–ø–∞
        # –ù–∞–ø—Ä–∏–º–µ—Ä: <b>text1 <b>text2</b> text3</b> -> <b>text1 text2 text3</b>
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤–ª–æ–∂–µ–Ω–Ω—ã–µ bold —Ç–µ–≥–∏
        html_text = re.sub(r'<b>([^<]*)<b>([^<]*)</b>([^<]*)</b>', r'<b>\1\2\3</b>', html_text)
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤–ª–æ–∂–µ–Ω–Ω—ã–µ italic —Ç–µ–≥–∏  
        html_text = re.sub(r'<i>([^<]*)<i>([^<]*)</i>([^<]*)</i>', r'<i>\1\2\3</i>', html_text)
        
        # –£–±–∏—Ä–∞–µ–º –ø–µ—Ä–µ—Å–µ–∫–∞—é—â–∏–µ—Å—è —Ç–µ–≥–∏: <b>text1 <i>text2</b> text3</i> -> <b>text1</b> <i>text2 text3</i>
        # –≠—Ç–æ –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω–∞—è –∑–∞–¥–∞—á–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç–æ–π –ø–æ–¥—Ö–æ–¥
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –æ—Ç–∫—Ä—ã–≤–∞—é—â–∏–µ –∏ –∑–∞–∫—Ä—ã–≤–∞—é—â–∏–µ —Ç–µ–≥–∏
        tags_to_check = ['b', 'i', 'u', 's', 'code', 'pre']
        
        for tag in tags_to_check:
            open_count = len(re.findall(f'<{tag}>', html_text))
            close_count = len(re.findall(f'</{tag}>', html_text))
            
            if open_count != close_count:
                logger.warning("–ù–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ç–µ–≥–æ–≤ {}: –æ—Ç–∫—Ä—ã–≤–∞—é—â–∏—Ö={}, –∑–∞–∫—Ä—ã–≤–∞—é—â–∏—Ö={}", 
                             tag, open_count, close_count)
                
                # –ü—Ä–æ—Å—Ç–æ–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ - —É–±–∏—Ä–∞–µ–º –≤—Å–µ —Ç–µ–≥–∏ —ç—Ç–æ–≥–æ —Ç–∏–ø–∞
                html_text = re.sub(f'</?{tag}>', '', html_text)
        
        # –£–±–∏—Ä–∞–µ–º –ø—É—Å—Ç—ã–µ —Ç–µ–≥–∏
        for tag in tags_to_check:
            html_text = re.sub(f'<{tag}></{tag}>', '', html_text)
            html_text = re.sub(f'<{tag}>\\s*</{tag}>', '', html_text)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å –±–∞–∑–æ–≤—ã–º –ø–∞—Ä—Å–µ—Ä–æ–º
        try:
            import xml.etree.ElementTree as ET
            # –û–±–æ—Ä–∞—á–∏–≤–∞–µ–º –≤ –∫–æ—Ä–Ω–µ–≤–æ–π —ç–ª–µ–º–µ–Ω—Ç –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
            wrapped = f"<root>{html_text}</root>"
            ET.fromstring(wrapped)
            logger.debug("HTML –ø—Ä–æ—à–µ–ª –≤–∞–ª–∏–¥–∞—Ü–∏—é")
        except ET.ParseError as e:
            logger.warning("HTML –Ω–µ –ø—Ä–æ—à–µ–ª –≤–∞–ª–∏–¥–∞—Ü–∏—é XML: {}, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º plain text", str(e))
            # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–µ–∫—Å—Ç –±–µ–∑ —Ç–µ–≥–æ–≤
            clean_text = re.sub(r'<[^>]+>', '', html_text)
            return escape(clean_text)
        
        return html_text
        
    except Exception as e:
        logger.error("–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ HTML: {}", str(e))
        # –í —Å–ª—É—á–∞–µ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–π –æ—à–∏–±–∫–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π plain text
        from html import escape
        clean_text = re.sub(r'<[^>]+>', '', html_text)
        return escape(clean_text)